<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>第2.0讲：决策树模型 - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#tutorial">tutorial</a>&nbsp;»&nbsp;<a href="/wiki/#tutorial-ml">ml</a>&nbsp;»&nbsp;第2.0讲：决策树模型</div>
</div>
<div class="clearfix"></div>
<div id="title">第2.0讲：决策树模型</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">关于</a></li>
<li><a href="#_2">回顾决策树</a></li>
<li><a href="#_3">决策树生成算法</a><ul>
<li><a href="#_4">信息熵</a></li>
<li><a href="#_5">信息增益准则</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="_1">关于</h2>
<p>本讲内容将通过一个例子，深入理解决策树模型。在这一讲中，你将学习到：</p>
<ol>
<li>什么是决策树模型？</li>
<li>构建决策树模型的算法是怎么实现的？</li>
</ol>
<p>学习本讲，希望你</p>
<ol>
<li>至少有高中数学水平。</li>
<li>如果你需要完成实践部分，需要有基本的 python 知识，你可以通过<a href="/wiki/tutorial/ml/intro-python.html">python快速入门</a>快速了解python如何使用。</li>
</ol>
<h2 id="_2">回顾决策树</h2>
<p>在上一讲中，我们简单了解了一下决策树的基本概念。如下图所示，是我们上一讲通过数据分析，设计出来的简单规则模型对应的决策树。决策树首先是一颗树，树由很多节点构成。这些节点分为两类，中间节点（椭圆形）和叶子节点（方形）。中间节点代表一条规则，叶子节点代表模型的决策输出。有多少个叶子结点，就代表有多少条规则。这个决策树实际上代表3条规则，每条规则可以用一个 IF-THEN 条件语句表示：</p>
<p><img alt="决策树" src="/wiki/static/images/dt-01.png" /></p>
<ol>
<li>IF 花瓣长度(petal length) &lt; 2.8, THEN sentosa</li>
<li>IF 花瓣长度(petal length) &gt;= 2.8 AND 花瓣长度(petal length) &lt; 4.9, THEN versicolor</li>
<li>IF 花瓣长度(petal length) &gt;= 4.9, THEN virginica</li>
</ol>
<p>这三个规则，共同定义了一个分段函数！</p>
<p>$$<br />
y =<br />
\begin{cases}<br />
0, \text{petal length} \lt 2.8 \\<br />
1, \text{petal length} \in [2.8, 4.9) \\<br />
2, \text{petal length} \ge 4.9<br />
\end{cases}<br />
$$</p>
<p>对于决策树，我们先定义几个基本概念，便于后面表述：</p>
<ul>
<li>子节点：和节点相连的后继节点，比如节点(petal length &lt; 4.9)是节点(petal length &lt; 2.8)的子节点</li>
<li>父节点：当前节点是子节点的父节点。比如节点(petal length &lt; 2.8)是节点(petal length &lt; 4.9)的父节点</li>
<li>边：两个相连节点中间的叫边，这条边有方向，从父节点指向子节点。</li>
<li>中间节点：有子节点的节点，它不直接输出预测结果的节点，对应一个规则</li>
<li>叶子节点：没有子节点的节点，直接输出预测结果的节点，对应一个复杂的规则，通常是多个规则的组合</li>
<li>根节点：没有父节点的节点</li>
<li>路径：从根节点出发，沿着子节点移动，到达叶子节点时所经历的所有节点序列就是一条路径。路径上边的数量叫做路径长度，实际上也等于中间节点的数目。</li>
<li>深度：最大的路径长度，比如上述决策树深度为2.</li>
<li>规则：一个可以判定真假的表达式就叫规则，比如花瓣长度(petal length) &lt; 2.8</li>
<li>组合规则：多个规则通过且(AND)和或(OR)连接起来的语句叫做组合规则，比如 花瓣长度(petal length) &gt;= 2.8 AND 花瓣长度(petal length) &lt; 4.9</li>
</ul>
<h2 id="_3">决策树生成算法</h2>
<p>在前面一讲，我们通过数据可视化分析，找到了针对花瓣长度(petal length)的3个规则。寻找这些规则的过程能不能够自动化完成呢？如果可以的话，那么决策树就可以自动化地生成了，不用再去做数据分析了。答案是肯定的，这就是决策树生成算法。</p>
<p>假设我们对花瓣长度设计规则，一个规则可以看做将它的取值划分成两个区间，关键是找到分割点的值。最简单的方法是，随机取一个分割点。</p>
<p><img alt="随机分割" src="/wiki/static/images/dt-02.png" /></p>
<p>如图所示，是两个不同的分割方式，第一种采用的分割点是2，在训练样本中，三个类别的样本数目都是50个，通过分割后，落到左边子节点的样本数目分别是[50, 0, 0]，即只有第1类的样本，看起来区分性还不错，把第一类完美地识别出来了；落到右边子节点的样本数目分别是[0, 50, 50]，第2类和第3类暂时还无法区分，不过不用担心，我们可以沿着右子节点继续分割下去就可能把这两类也分开来。第二种分割方式采用的分割点是4，相比于第一种分割方式，它把11个第2类样本也放到左边了，看起来区分性没第一种好。那么问题来了，怎么衡量一种分割方式比另外一种好呢？</p>
<h3 id="_4">信息熵</h3>
<p>信息熵可以用来度量一个概率分布$\{p_i, i=1,2,...\}$的不确定度，熵的定义是</p>
<p>$$<br />
H(\{p_i\}) = -\sum_i p_i \log p_i<br />
$$</p>
<p>为什么熵可以度量不确定度呢？我们来看看最简单的一个例子，假设我们抛一枚硬币，如果硬币是均匀的，那么正面和反面出现的概率都是0.5，我们计算一下熵$H = - 0.5\log 0.5 - 0.5\log0.5=\log 2 = 1$（这里为方便记，对数的底取为2）。如果这个硬币不那么均匀，假设正面朝上的概率为0.9，反面朝上的概率为0.1，我们再来计算一下熵 $H =  - 0.9\log 0.9 - 0.1\log0.1=0.427$。熵变小了！直观来看是不确定性减小了！因为抛一枚均匀的硬币，确实很难猜测它是正面还是反面，但是如果非常不均匀的硬币，正面朝上的概率是0.9，那么我们有很大的把握猜测它是正面！如果我们把熵H随着正面朝上概率p画一个函数图像，可以看到它在0.5处取最大值，直观理解是均匀的硬币最难猜，相反在0和1处取最小值，直观理解是只有一面的硬币最好猜！</p>
<p><img alt="熵" src="/wiki/static/images/entropy_plot.svg" /></p>
<p>信息熵的另外一个解释是，要描述一个事情所需要的最少比特数。比特是计算表达数据量的一个单位，计算机中都是用0和1表示数据，1位这样的0/1单元就是1比特。所以这句话也可以这样理解，如果我要用计算机存储这样一个事件，最少要用的数据量。对于一个均匀硬币，我要记录结果是正面还是反面，我只要用0表示反面，1表示正面，这样只需要1个比特（恰好等于熵）就可以记录结果了。但是如果一枚非常不均匀的硬币，正面朝上的概率为1，那么我们根本不需要记录就可以知道它的结果肯定是正面，对应的熵为0！</p>
<h3 id="_5">信息增益准则</h3>
<p>利用信息熵，我们可以度量每一种分割方法的好坏。因为熵的意义是不确定度，那么我们计算分割前后这种不确定度的减少量，不确定度的减少越多，说明分割后越好区分每一类，所以分割越好。</p>
<p><img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /></p>
</div>
<div>
    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-02-06 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '第2.0讲：决策树模型',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/tracholar/wiki" target="_blank"> github </a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>