<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>第1.0讲：一个例子入门机器学习 - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#tutorial">tutorial</a>&nbsp;»&nbsp;<a href="/wiki/#tutorial-ml">ml</a>&nbsp;»&nbsp;第1.0讲：一个例子入门机器学习</div>
</div>
<div class="clearfix"></div>
<div id="title">第1.0讲：一个例子入门机器学习</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">关于</a></li>
<li><a href="#_2">机器学习的本质</a><ul>
<li><a href="#_3">机器学习历史简述</a></li>
<li><a href="#_4">机器学习可以干啥</a></li>
</ul>
</li>
<li><a href="#0">从0开始机器学习</a><ul>
<li><a href="#_5">任务与数据</a></li>
<li><a href="#_6">建模</a><ul>
<li><a href="#_7">简单规则模型</a></li>
<li><a href="#_8">决策树模型</a></li>
<li><a href="#_9">线性模型</a></li>
</ul>
</li>
<li><a href="#_10">预测</a></li>
</ul>
</li>
<li><a href="#_11">总结</a></li>
<li><a href="#_12">作业</a></li>
</ul>
</div>
<h2 id="_1">关于</h2>
<p>本讲内容将通过一个例子，入门机器学习。在这一讲中，你将学习到：</p>
<ol>
<li>什么是机器学习？</li>
<li>机器学习能做什么？</li>
<li>机器学习在代码上具体如何实现？</li>
</ol>
<p>学习本讲，希望你</p>
<ol>
<li>有基本的 python 知识，你可以通过<a href="/wiki/tutorial/ml/intro-python.html">python快速入门</a>快速了解python如何使用。</li>
</ol>
<h2 id="_2">机器学习的本质</h2>
<h3 id="_3">机器学习历史简述</h3>
<p>现在人们通常将机器学习和人工智能联系在一起，实际上，人工智能涉及的领域更加宽泛，机器学习只是其中一种手段。人工智能的起源可以追溯到上世纪50年代，1956年举办的达茂思会议(<a href="https://en.wikipedia.org/wiki/Dartmouth_Workshop">Dartmouth Conference</a>)，在这次会议上，信息论之父Shannon和IBM科学家Nathan Rochester等人，一起探讨了一个议题：精确地描述学习过程和智能的特征并用机器进行模拟。</p>
<p>人工智能发展的初期，研究者致力于将人类的知识表达为一些逻辑规则，然后利用搜索进行逻辑推理，进而实现智能，到后来演变到利用知识库构造专家系统，实现所谓的智能。这期间，比较有名的成就有IBM的国际象棋程序深蓝打败国际象棋冠军。这一阶段的人工智能实现，更像人类的演绎推理，利用少量的规则，加上知识库，进行推演，从而得出结论。但是，规则的归纳需要人类专家干预，限制了这种模式的发展。2000年以后，随着互联网和摩尔定律的发展，产生了大量的数据和计算资源，使得人们可以利用机器从数据中自动归纳出规则，也就是数据驱动的智能。这其中的工具就是机器学习！</p>
<p>所以，<strong>机器学习就是利用一种程序从数据中自动归纳出有价值的知识的一种方法</strong>。</p>
<h3 id="_4">机器学习可以干啥</h3>
<p>具体来讲，机器学习可以用来做很多事情，目前已经有成功案例的就有很多。例如</p>
<ul>
<li>计算广告：利用用户历史的行为数据，做广告的点击率(CTR)预估 <a href="https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html">https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html</a></li>
<li>推荐系统：利用用户历史行为做商品推荐 <a href="https://book.douban.com/subject/10769749/">https://book.douban.com/subject/10769749/</a></li>
<li>游戏：Alpha Go <a href="https://deepmind.com/research/alphago/">https://deepmind.com/research/alphago/</a></li>
<li>金融：大数据风控</li>
<li>自然语言处理：机器翻译</li>
<li>语音识别</li>
<li>图像识别</li>
<li>etc</li>
</ul>
<p>接下来，我们就用一个实际的例子来解释机器学习是如何从数据中学到有用知识的。</p>
<h2 id="0">从0开始机器学习</h2>
<p>接下来，我们将利用一个简单的分类任务，给读者展示机器学习如何从数据中学到有用知识的。强烈建议您跟着这个教程亲自动手操作一遍，为此，您需要做一下准备工作。</p>
<ul>
<li>安装 Python <a href="https://www.python.org/downloads/release/python-2713/">https://www.python.org/downloads/release/python-2713/</a></li>
<li>安装Python包<ul>
<li>scikit-learn <a href="http://scikit-learn.org/stable/install.html">http://scikit-learn.org/stable/install.html</a></li>
<li>pandas</li>
<li>matplotlib, seaborn, graphviz 绘图</li>
</ul>
</li>
</ul>
<h3 id="_5">任务与数据</h3>
<p>本任务采用鸢尾花(iris)数据集，你可以从UCI网站上下载<a href="https://archive.ics.uci.edu/ml/datasets/Iris">https://archive.ics.uci.edu/ml/datasets/Iris</a>。如果已经安装了 scikit-learn，那么可以利用提供的dataset接口直接调用。鸢尾花数据集是著名的统计学家 Fisher 提供的。下面我们用一段简单的Python代码加载该数据集看一看。</p>
<div class="hlcode"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sn</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-talk&#39;</span><span class="p">)</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># 随机选取几条数据</span>
<span class="n">idx</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

<span class="k">print</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span>
<span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>


<div class="hlcode"><pre><span></span>[&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;]
</pre></div>


<table>
<thead>
<tr>
<th></th>
<th>sepal length (cm)</th>
<th>sepal width (cm)</th>
<th>petal length (cm)</th>
<th>petal width (cm)</th>
<th>target</th>
</tr>
</thead>
<tbody>
<tr>
<td>91</td>
<td>6.1</td>
<td>3.0</td>
<td>4.6</td>
<td>1.4</td>
<td>1</td>
</tr>
<tr>
<td>77</td>
<td>6.7</td>
<td>3.0</td>
<td>5.0</td>
<td>1.7</td>
<td>1</td>
</tr>
<tr>
<td>99</td>
<td>5.7</td>
<td>2.8</td>
<td>4.1</td>
<td>1.3</td>
<td>1</td>
</tr>
<tr>
<td>65</td>
<td>6.7</td>
<td>3.1</td>
<td>4.4</td>
<td>1.4</td>
<td>1</td>
</tr>
<tr>
<td>14</td>
<td>5.8</td>
<td>4.0</td>
<td>1.2</td>
<td>0.2</td>
<td>0</td>
</tr>
<tr>
<td>108</td>
<td>6.7</td>
<td>2.5</td>
<td>5.8</td>
<td>1.8</td>
<td>2</td>
</tr>
<tr>
<td>142</td>
<td>5.8</td>
<td>2.7</td>
<td>5.1</td>
<td>1.9</td>
<td>2</td>
</tr>
<tr>
<td>127</td>
<td>6.1</td>
<td>3.0</td>
<td>4.9</td>
<td>1.8</td>
<td>2</td>
</tr>
<tr>
<td>24</td>
<td>4.8</td>
<td>3.4</td>
<td>1.9</td>
<td>0.2</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>该数据集的每一条记录代表一个样本，每一个样本有4个属性变量：</p>
<ul>
<li>sepal length (cm) 萼片长度</li>
<li>sepal width (cm) 萼片宽度</li>
<li>petal length (cm) 花瓣长度</li>
<li>petal width (cm) 花瓣宽度</li>
</ul>
<p>每一个样本有1个目标变量target，target有3个取值，每一种取值的意义如下：</p>
<ul>
<li>0： setosa 山鸢尾</li>
<li>1： versicolor 变色鸢尾</li>
<li>2： virginica 维吉尼亚鸢尾</li>
</ul>
<p>每一种鸢尾花的图片如下，从左到右分别是 setosa,versicolor,virginica</p>
<p><img alt="Iris" src="/wiki/static/images/iris.png" /></p>
<h3 id="_6">建模</h3>
<p>我们的目标是，建立一个模型，输入鸢尾花的4个属性变量，能够对鸢尾花的种类进行判别。这样一旦模型建立好了之后，对新看到的鸢尾花，只要测量了这4个属性，就可以利用模型对它的类别进行预测了。</p>
<p>数学地角度来说，我们要确定一个函数 $f: R^4 \rightarrow {0,1,2}$，输入是一个4维向量 $\vec{x} = (x_1, x_2, x_3, x_4)$，每一维代表一个属性变量的值，输出一个分类变量 $y \in {0,1,2}$，代表该样本属于哪个类别。所谓的建模过程，就是利用我们已经观测到的数据集，去确定这个函数 $f$ 的具体形式和参数。这里每一个属性我们都称作一个特征，输出分类变量我们陈做目标（或建模目标），这里的函数 $f$ 就是我们通常所说的模型。</p>
<h4 id="_7">简单规则模型</h4>
<p>在建立复杂模型之前，我们先来建立一种简单规则模型。所谓的简单规则，就是对一个属性，通过规则判定，确定该样本属于哪一个类。比如，我们可以进行数据分析，观察每一种花的萼片长度、萼片宽度、花瓣长度、花瓣宽度的平均值。</p>
<div class="hlcode"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;petal length (cm)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;petal width (cm)&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;petal length (cm)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;petal width (cm)&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;平均值&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="svg" src="/wiki/static/images/iris-01.svg" /></p>
<p><img alt="svg" src="/wiki/static/images/iris-02.svg" /></p>
<p>通过上述分析，可以看到三种花的花瓣长度(petal length)差异比较大，setosa的平均花瓣长度在1.5cm左右，versicolor的平均花瓣长度在4.2cm左右，而 virginica的平均花瓣长度在5.6cm左右。因此，一种简单规则模型可以归纳为</p>
<p>$$<br />
target =<br />
\begin{cases}<br />
0, \text{petal length} \lt 2.8 \\<br />
1, \text{petal length} \in [2.8, 4.9) \\<br />
2, \text{petal length} \ge 4.9<br />
\end{cases}<br />
$$</p>
<p>这里分割点的值取的是两种花平均中的平均数。</p>
<p>好了，到目前为止，你已经学会了数据挖掘过程中的最简单情景了。通过数据分析，归纳出规则，然后将规则编码成一个函数，从而得到一个预测模型，可以用来做预测。</p>
<p>很快，我们会发现，这种方法需要人工进行数据分析，总结出规则，那么能不能够让程序自动地找到这些规则，甚至发现更复杂的规则呢？答案是肯定的，决策树就是这样一种模型，自动地发现这些规则，甚至高阶组合规则。</p>
<h4 id="_8">决策树模型</h4>
<p>前面我们已经说过，决策树是这样一种模型，它可以自动地发现一些区分目标的规则，甚至高阶组合规则。决策树如何发现这些规则我们暂时不要去深究，作为一个入门课程，我们重点是了解模型能干啥。这里，我们利用 scikit-learn 软件包里面的决策树模型工具，建立模型。</p>
<p>决策树模型分为回归和分类，如果目标变量是类别变量，这样的问题成为分类，我们这个任务就是分类。而如果目标变量是连续变量，例如预测房价，那么这样的问题就是回归。这里我们只用分类就好了，对应的类是 <code>DecisionTreeClassifier</code>，为了便于观察，我们限定树的深度为2。为了让决策树模型能够从数据中学会规则，我们需要调用模型的 <code>fit</code> 方法，并将数据（包括特征<code>iris.data</code>和目标<code>iris.target</code>）传给它。</p>
<p>模型从数据中自动学会这些规则的过程，我们称之为<strong>训练</strong>或者<strong>拟合</strong>。因此，<code>fit</code>方法实际上就是在做<strong>模型训练</strong>！</p>
<p>模型训练好了之后，我们可以将决策树画出来，进行观察。</p>
<div class="hlcode"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">export_graphviz</span>
<span class="kn">import</span> <span class="nn">graphviz</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>

<span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span>
                           <span class="n">class_names</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span>
                           <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
</pre></div>


<p><img alt="svg" src="/wiki/static/images/iris-3.svg" /></p>
<p>决策树模型是由规则组成的一棵决策树，它的节点分为内部节点和叶子节点。内部节点对应一条分裂规则，叶子节点对应一个判决或者输出，对于分类任务输出的类别是满足这个规则样本最多的那个类别。</p>
<p>上面的决策树是一颗二叉树，根节点对应规则是petal length (cm) &lt;= 2.45，如果满足这条规则，就到了左子树，左子树是一个叶子节点，满足这条规则到达左子树的样本有50个，且全部为setosa这个类别，因此输出类别是 setosa。</p>
<p>这和前面我们通过数据分析得出的规则 petal length &lt; 2.8 则为setosa，非常接近。</p>
<h4 id="_9">线性模型</h4>
<p>线性模型和决策树模型行为完全不同，线性模型的出发点是对每一类，计算一个分数</p>
<p>$$<br />
score_i = b_i + \vec{w} _ i^T \vec{x}<br />
$$</p>
<p>然后选择出得分最大的类作为预测的类。模型的权重$\vec{w} _ i$称作模型参数，通过优化算法优化得到。优化模型参数的过程就叫做模型训练！</p>
<p>线性模型（确切地说是线性多分类模型）里面最典型的是多分类逻辑回归，它将每个类的分数做归一化，得到样本归属于该类的概率</p>
<p>$$<br />
P(i|\vec{x}) = \frac{e^{score_i}}{\sum_i e^{score_i}}<br />
$$</p>
<p>下面利用<code>scikit-learn</code>多分类逻辑回归工具 <code>LogisticRegression</code> 进行建模。</p>
<div class="hlcode"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;权重&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="svg" src="/wiki/static/images/iris-4.svg" /></p>
<p>从模型参数来看，sepal length 和 sepal width 数值大的类别setosa的得分更高，petal length 数值较大的 versicolor的得分更高，petal length 和 petal width 数值大的 virginica 得分更高。</p>
<h3 id="_10">预测</h3>
<p>一旦模型建立好了之后，我们就可以利用模型进行预测了，所谓的预测，是指对于一个新的样本，比如我在某个路边看到了一朵鸢尾花，不知道到底是哪一类，就可以利用这个模型进行预测。首先，我们需要测量模型预测所需要的4个数据（特征），花萼的长度和宽度，花瓣的长度和宽度，然后输入的模型中去。</p>
<p>对预测前面简单规则模型，只需要花瓣的长度数据即可预测。对于决策树模型，实际上只需要花瓣的长度和宽度数据也可预测，如果我们将决策树深度变得更深，那么就可能要用到所有数据。首先，决策树从根节点开始搜索，根节点对应一条规则 petal length (cm) &lt;= 2.45，如果满足这条规则，就到左子树，预测输出为setosa。如果不满足，那么就到右子树，右子树根节点还是一个规则 petal width (cm) &lt;= 1.75。我们重复这个过程，直到找到该样本满足规则的叶子节点，叶子节点对应的输出值就是模型预测结果。</p>
<h2 id="_11">总结</h2>
<p>这里我们以鸢尾花分类任务为例，构建了一个决策树模型进行预测。总结起来，所谓的建模过程，就是利用已有的标注数据（已知目标变量的值的数据），自动学习到一个函数 $f:R^n \rightarrow Y$，根据观察到的特征向量，计算得到目标变量的值。这个任务就是一个3分类的函数。虽然这个任务简单，但是和更复杂的任务都具有以下3个基本步骤：</p>
<ul>
<li>收集（标注）数据</li>
<li>建立模型</li>
<li>预测</li>
</ul>
<p>不同的业务可能收集到的数据不同，收集到的原始数据需要加工成模型能用的数据（即特征）。</p>
<p>不同的任务可以设立不同的目标进行建模，比如预测性别，那么目标变量是男和女；预测年龄，那么目标变量是个0-100之间的连续值；预测股价涨跌，那么目标变量就是涨和跌。</p>
<p>相同数据和目标的情况下，也可以选择不同的模型，决策树是一个久经沙场的模型，它的两个变体<strong>随机森林</strong>和<strong>梯度提升树</strong>应用非常广泛。近年来的深度神经网络，可以利用非常原始的数据进行建模，减少了人工特征工程的工作量。但是本质上，他们都在干同一件事情，学习这样一个函数！</p>
<h2 id="_12">作业</h2>
<p>一个编程小练习，探索决策树的深度与预测的准确率的关系，并解释一下观察到的现象的原因。</p>
<div class="hlcode"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sn</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-talk&#39;</span><span class="p">)</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="n">depths</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>

<span class="sd">&quot;&quot;&quot;下面是你的代码，请完成功能：</span>
<span class="sd">   1. 用深度为2-10的不同决策树分别对数据进行建模，计算每一颗决策树的预测准确率。准确率是预测正确的样本数目 / 总样本数目。</span>
<span class="sd">   2. 画出深度-误差的折线图</span>

<span class="sd">   Hint:</span>
<span class="sd">      1. sklearn每一个模型都会有一个`predict`方法，可以用来预测结果。</span>
<span class="sd">      2. matplotlib 的画图函数 `plt.plot` 是有用的画图工具。</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>


<p><img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /></p>
</div>
<div>
    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-02-05 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '第1.0讲：一个例子入门机器学习',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/tracholar/wiki" target="_blank"> github </a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>