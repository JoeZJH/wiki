<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>第10.0讲：强化学习简介 - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#tutorial">tutorial</a>&nbsp;»&nbsp;<a href="/wiki/#tutorial-ml">ml</a>&nbsp;»&nbsp;第10.0讲：强化学习简介</div>
</div>
<div class="clearfix"></div>
<div id="title">第10.0讲：强化学习简介</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">关于</a></li>
<li><a href="#_2">马尔科夫决策过程</a></li>
</ul>
</div>
<h2 id="_1">关于</h2>
<p>强化学习近年大火，最早是因为AlphaGo使用强化学习打败人类围棋冠军引发的。在那之后，强化学习在工业场景应用越来越多，原来很多做搜索、推荐、广告等一直在用监督学习的业务，也开始使用强化学习来优化用户体验和平台收益了。强化学习实际上很早就提出了，事实上，强化学习来源于控制论。控制论之父叫做<a href="https://en.wikipedia.org/wiki/Norbert_Wiener">维纳</a>，学过信号处理的可能知道他，维纳滤波就是用他的名字命名的。控制论最早源于航天，人们要控制火箭发射装置，将火箭发射到地球之外；控制论还源于机器人控制，人们需要用算法对机器人的行为进行控制。所以，很多讲强化学习的文献也会说强化学习是在优化控制策略。</p>
<p>在这篇文章中，您将学习到</p>
<ol>
<li>强化学习是什么？可以干什么？</li>
<li>马尔科夫决策过程(MDP)的重要概念</li>
<li>哈密顿-雅克比-贝尔曼(HJB)方程</li>
<li>已知环境下HJB方程的求解算法：值迭代和策略迭代</li>
</ol>
<p>我期望您至少有：</p>
<ol>
<li>高中数学水平且年满18岁</li>
<li>如果你需要完成实践部分，需要有基本的 python 知识，你可以通过<a href="/wiki/tutorial/ml/intro-python.html">python快速入门</a>快速了解python如何使用。</li>
</ol>
<h2 id="_2">马尔科夫决策过程</h2>
<p>考虑下面的迷宫游戏问题，你控制一个机器人在一个二维迷宫中运动，迷宫中有正常的陆地、火坑、石柱、钻石。你可以控制机器人上下左右运动，机器人不能走到迷宫外面，一次最多只能运动一步，如果不小心掉到火坑中，游戏结束，如果找到了钻石，那么可以得到奖励！由于你的控制是通过语音指令控制，机器人有一定概率会判断出错。比如你说让机器人往左走，机器人有一定概率会往右走，所以机器人的移动和你的指令之间并不是完美匹配的。你的目标是通过设计策略，让机器人尽快地找到钻石，获得奖励。</p>
<p><img alt="MDP迷宫" src="/wiki/static/images/mdp-01.png" /></p>
<p>上述问题有几个关键要素：</p>
<ol>
<li>状态：机器人所处的位置是有限的，我们把每一个位置称作一个状态，那么一共有15个状态（有一个是石柱，机器人无法到达这个位置）。其中两个是火坑，一个是钻石，由于机器人进入这些状态就会结束游戏，我们称为终态。我们用S来表示状态，那么S可以有15个取值，我们一次用数字标识这15个状态，那么$S \in \{1,2,...,15 \} $。</li>
<li>动作：在每个不是终态的状态下，我们都有4个控制动作，上、下、左、右，我们依次编号为1到4，用A表示动作，那么$A \in \{1,2,3,4 \}$。</li>
<li>转移概率：因为我们是通过声音控制机器人的，所以机器人可能听错，可以认为是语音识别技术尚不成熟的原因。那么在某个状态S下，采取动作A之后，机器人到达的状态并不是完全确定的。例如当机器人在左上角时，采取“右”这个动作时，机器人也有一定概率会向下移动，进入状态5（假设状态按照从左到右顺序编号）。为了描述机器人的这种不确定运动，可以用一个转移概率来表示。我们用P(S'|S, A)表示在状态S下，采取动作A的条件下，机器人进入状态S'的概率。例如在刚才这个例子中，P(S'=5|S=1, A=4)就表示在状态1（也就是左上角），采取动作4（也就是“右”）的条件下，进入状态5（也就是第二行第一个状态）的概率。所以，这个转移概率描述的是外界环境在我们的控制下变化的规律。</li>
<li>回报：在机器人每一步运动到下一个状态时，环境会给我们一个奖励或者惩罚，例如如果进入火坑游戏就会结束，而拿到钻石就会得到奖励，这种奖励或者惩罚我们用数量来量化。我们可以用正数表示奖励，负数表示惩罚，这就是回报。一般情况下，回报可能跟状态和动作都有关系，所以我们用一个函数来表示  R(S, A, S')，它表示在在状态S下采取动作A到达状态S'时，获得的回报。</li>
<li>马尔科夫性：描述环境的转移概率只跟当前状态有关，而与之前经过的状态无关，这种性质叫做马尔科夫性（因为是一个叫马尔科夫的人最早提出来的）。在这个例子中，机器人在我们的控制下要进入的状态只与当前的状态和我们的控制动作有关，而与在这之前机器人经历过的状态无关。并不是所有的决策事情都有马尔科夫性的，比如股票，今天涨跌不但与昨天有关，还与之前的多天有关。</li>
</ol>
<p><img alt="MDP" src="/wiki/static/images/mdp-02.png" /></p>
<p>上述问题可以抽象为上述4个要素和1个性质的普遍问题，因为环境具有马尔科夫性，我们需要做出决策对机器人进行控制，所以叫做马尔科夫决策过程(Markov decision process，MDP)。对于这类问题，我们在每一步决定要采取那个动作的策略可以用一个策略函数来表示$\pi(A | S)$，这个函数的意义是在状态S下，采用动作A的概率。对于确定性的策略可以看做它的一个特例，即只有一个动作的概率为1其他为0.例如，我们可以定义一个确定性策略如下：如果右边能走，就往“右”，如果右边不能走，就往“下”。用数学公式表示为</p>
<p>$$<br />
\pi(A | S) = \begin{cases}<br />
            4, S \in \{1,2,3,6,8,9,10,12,13,14 \} \\<br />
            2, S \in \{4,7,11 \}<br />
            \end{cases}<br />
$$</p>
<p>MDP问题的目标是找到这样一个策略，在这个策略下，总的折扣回报最大化！总折扣回报定义如下</p>
<p>$$<br />
R = \sum_{t=1}^{\infty} \gamma^{t-1} R(S_t, A_t, S' _ t), \gamma \in (0, 1]<br />
$$</p>
<p>也就是在这个策略下，将所有获得的回报打个折之后全部加起来。越往后的折扣越大，这是因为我们更关心离当前时间更近的回报。这个回报越大，说明这个策略越好，使得回报最大的策略就是最优策略。</p>
<p>以上述迷宫为例，我们假定游戏结束后回报全部为0，状态也不改变了。那么上述求和只到游戏结束，假设折扣因子为1，跳到火坑的回报为-1，找到钻石的回报为+1，其他情况回报为0。那么一个找到钻石的策略的总回报就是1！而跳到火坑的策略的总回报为-1.</p>
</div>
<div>
    <img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" />

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-02-06 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '第10.0讲：强化学习简介',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/tracholar/wiki" target="_blank"> github </a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>