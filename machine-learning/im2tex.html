<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>What You Get Is What You See: A Visual Markup Decompiler - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;What You Get Is What You See: A Visual Markup Decompiler</div>
</div>
<div class="clearfix"></div>
<div id="title">What You Get Is What You See: A Visual Markup Decompiler</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">关于</a></li>
<li><a href="#_2">导言</a></li>
<li><a href="#problem-image-to-markup-generation">Problem: Image-to-Markup Generation</a></li>
<li><a href="#wygiwys">模型 WYGIWYS</a></li>
</ul>
</div>
<h2 id="_1">关于</h2>
<p>论文：What You Get Is What You See: A Visual Markup Decompiler</p>
<h2 id="_2">导言</h2>
<p>OCR用来识别并提取结构信息：不仅仅要识别文字，还要提取语义。<br />
数学表达式OCR系统：INFTY系统。<br />
需要联合处理图片和文字信息。</p>
<p>文章使用的模型是对模型 <strong>attention-based encoder-decoder model (Bahdanau, Cho, and Bengio 2014)</strong> 的简单扩展。</p>
<blockquote>
<p>The use of attention addi- tionally provides an alignment from the generated markup to the original source image</p>
</blockquote>
<p>数据集：IM2LATEX-100K</p>
<p>在线效果演示：<a href="http://lstm.seas.harvard.edu/latex/">http://lstm.seas.harvard.edu/latex/</a></p>
<h2 id="problem-image-to-markup-generation">Problem: Image-to-Markup Generation</h2>
<ul>
<li>图像：$(x \in \mathcal{X})$，例如$(\mathcal{X} = \mathbb{R}^{H \times W})$。</li>
<li>文本：$(y = (y_1, y_2, ..., y_C); y \ in \mathcal{Y}, y_i \in \Sigma)$。</li>
<li>编译：$(\mathcal{Y} \rightarrow \mathcal{X})$.</li>
<li>需要学习一个反编译器！</li>
<li>训练：利用样本$((x, y))$训练学习一个反编译器。</li>
<li>测试：利用模型预测的$(\hat{y})$和编译函数，生成一个图像$(\hat{x})$，要求生成的图像和$(x)$一致。</li>
</ul>
<h2 id="wygiwys">模型 WYGIWYS</h2>
<p><img src="/wiki/static/images/im2tex.png" style="width:500px; float:left;" /></p>
<ul>
<li>图像特征抽取：CNN，没有全连接层，抽取的特征V尺寸为 $(D \times H' \times W')$，分别是通道数，降维后的高度和宽度。</li>
<li>编码器：之前的ImageCaption不需要这个编码器，但是编码器可以学到顺序关系，这可以：<ol>
<li>学习 markup languages 的从左到右的顺序关系</li>
<li>使用周围的上下文去编码隐层表达</li>
</ol>
</li>
</ul>
<p>编码器使用RNN（LSTM）。隐层 feature grid $(\tilde{V}_{h,w} = \text{RNN}(\tilde{V}_{h,w-1}, V_{h, w}))$，<br />
即按行顺序编码，对每一行的初始状态$(\tilde{V}_{h,0})$，也是通过学习得到（怎么训练？作为一个参数一起学？），叫做 position embedding，可以表达图像所在位置信息。</p>
<ul>
<li>解码器：优点复杂<ol>
<li>通过上述编码后的特征 grid $(\tilde{V})$，加上历史隐层向量$(h_{t-1})$学习一个注意力向量$(\alpha_t)$</li>
<li>利用注意力向量和特征矩阵 $(\tilde{V})$ 学习一个有注意力的上下文向量 $(c_t)$</li>
<li>利用当前隐态向量 $(h_t)$ 和带有注意力的上下文 $(c_t)$ 学习一个输出向量 $(o_t)$，最终做softmax变换得到输出的词$(y_t)$！</li>
<li>隐态更新采用常规的Decoder方案，即上一时刻的隐态$(h_{t-1})$ 加上 上一时刻的输出 $(o_t, y_{t-1})$</li>
</ol>
</li>
</ul>
<p>$$</p>
<p>$$</p>
</div>
<div id="income">
    <img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" />

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div id="content-footer">created in <span class="create-date date"> 2016-09-25 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'What You Get Is What You See: A Visual Markup Decompiler',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>