<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>【KDD2018-Airbnb】Real-time Personalization using Embeddings for Search Ranking at Airbnb - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;【KDD2018-Airbnb】Real-time Personalization using Embeddings for Search Ranking at Airbnb</div>
</div>
<div class="clearfix"></div>
<div id="title">【KDD2018-Airbnb】Real-time Personalization using Embeddings for Search Ranking at Airbnb</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">摘要 &amp; 导言</a></li>
<li><a href="#methodology">METHODOLOGY</a><ul>
<li><a href="#listing-embeddingslist">Listing Embeddings(List指一个项目?还是列表?)</a></li>
<li><a href="#user-type-listing-type-embeddings">User-type &amp; Listing-type Embeddings</a></li>
<li><a href="#_2">试验</a></li>
</ul>
</li>
<li><a href="#_3">问题</a></li>
</ul>
</div>
<h2 id="_1">摘要 &amp; 导言</h2>
<ul>
<li>Airbnb 问题的特殊性<ul>
<li>是一个双边市场,既需要考虑考虑买家的体验,还需要考虑卖家的体验</li>
<li>用户很少有复购行为</li>
</ul>
</li>
<li>99%的转化来自于实时搜索排序和推荐</li>
<li>方法:pairwise regression, 下单的作为正例,拒绝的作为负例 <ul>
<li>lambda rank</li>
<li>联合优化买家和卖家的排序 ??</li>
<li>利用listing embeddings, low-dimensional vector representations计算用户交互的list与候选list的相似性,作为个性化特征放到排序模型中</li>
</ul>
</li>
<li>利用点击等行为学习短期兴趣;而利用下单学习长期兴趣<ul>
<li>问题: 下单行为过于稀疏, 一个用户平均一年旅行1-2次; 长尾用户只有一次下单</li>
<li>解决方法: 不是对userid做embedding,而是在用户类型维度做embedding,类型通过多对一的规则映射得到</li>
</ul>
</li>
<li>
<p>论文创新点:</p>
<ul>
<li>实时个性化</li>
</ul>
</li>
<li>
<p>相关论文:</p>
<ul>
<li>Yahoo<ol>
<li>MihajloGrbovic,NemanjaDjuric,VladanRadosavljevic,FabrizioSilvestri,Ri-cardo Baeza-Yates, Andrew Feng, <br />
   Erik Ordentlich, Lee Yang, and Gavin Owens. 2016. Scalable semantic matching of queries to ads in sponsored <br />
   search advertis- ing. In SIGIR 2016. ACM, 375–384.</li>
<li>MihajloGrbovic,VladanRadosavljevic,NemanjaDjuric,NarayanBhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp. 2015. <br />
   E-commerce in your inbox: Product recommendations at scale. In Proceedings of the 21th ACM SIGKDD <br />
   International Conference on Knowledge Discovery and Data Mining.</li>
<li>Dawei Yin, Yuening Hu, Jiliang Tang, Tim Daly, Mianwei Zhou, Hua Ouyang, Jianhui Chen, Changsung Kang, <br />
   Hongbo Deng, Chikashi Nobata, et al. 2016. Ranking relevance in yahoo search. In Proceedings of the 22nd ACM SIGKDD.</li>
</ol>
</li>
<li>Etsy<ol>
<li>Kamelia Aryafar, Devin Guillory, and Liangjie Hong. 2016. An Ensemble-based Approach to Click-Through <br />
   Rate Prediction for Promoted Listings at Etsy. In arXiv preprint arXiv:1711.01377.</li>
</ol>
</li>
<li>Criteo<ol>
<li>Thomas Nedelec, Elena Smirnova, and Flavian Vasile. 2017. Specializing Joint Representations for the task <br />
   of Product Recommendation. arXiv preprint arXiv:1706.07625 (2017).</li>
</ol>
</li>
<li>Linkedin<ol>
<li>Benjamin Le. 2017. Deep Learning for Personalized Search and Recommender Systems. In Slideshare:<br />
<a href="https://www.slideshare.net/BenjaminLe4/deep-learning-for-personalized-search-and-recommender-systems">https://www.slideshare.net/BenjaminLe4/deep-learning-for-personalized-search-and-recommender-systems</a>.</li>
<li>Thomas Schmitt, François Gonard, Philippe Caillou, and Michèle Sebag. 2017. Language Modelling for <br />
   Collaborative Filtering: Application to Job Applicant Matching. In IEEE International Conference on <br />
   Tools with Artificial Intelligence.</li>
</ol>
</li>
<li>Tinder<ol>
<li>SteveLiu.2017.PersonalizedRecommendationsatTinder:TheTinVecApproach. In Slideshare: <br />
<a href="https://www.slideshare.net/SessionsEvents/dr-steve-liu-chief-scientist-tinder-at-mlconf-sf-2017">https://www.slideshare.net/SessionsEvents/dr-steve-liu-chief-scientist-tinder-at-mlconf-sf-2017</a>.</li>
</ol>
</li>
<li>Tumblr<ol>
<li>MihajloGrbovic,VladanRadosavljevic,NemanjaDjuric,NarayanBhamidipati, and Ananth Nagarajan. 2015. <br />
   Gender and interest targeting for sponsored post advertising at tumblr. In Proceedings of the 21th <br />
   ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1819–1828.</li>
</ol>
</li>
<li>Instacart<ol>
<li>Sharath Rao. 2017. Learned Embeddings for Search at Instacart. In Slideshare: <br />
<a href="https://www.slideshare.net/SharathRao6/learned-embeddings-for-search-and-discovery-at-instacart">https://www.slideshare.net/SharathRao6/learned-embeddings-for-search-and-discovery-at-instacart</a>.</li>
</ol>
</li>
<li>Facebook<ol>
<li>Ledell Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, and Jason Weston. 2017. <br />
   StarSpace: Embed All The Things! arXiv preprint arXiv:1709.03856.</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="methodology">METHODOLOGY</h2>
<ul>
<li>listing embedding 短期实时个性化</li>
<li>user-type &amp; listing type embeddings 长期个性化</li>
</ul>
<h3 id="listing-embeddingslist">Listing Embeddings(List指一个项目?还是列表?)</h3>
<ul>
<li>session定义: $( s = (l_1, ..., l_M) )$ 非中断点击序列; 新的session定义为相继两次点击事件相隔30分钟以上。</li>
<li>skip-gram模型: 损失函数</li>
</ul>
<p>$$<br />
\mathbf{L} = \sum_{s\in S}\sum_{l_i \in s} \sum_{-m \le j \le m, i \ne 0} P(l_{i+j} | l_i)<br />
$$</p>
<p>利用负采样近似, 正例集合 $((l, c) \in D_p)$ l,c在同一个上下文; 负例集合 $( (l, c) \in D_n )$</p>
<p>$$<br />
\arg\max_{\theta} \sum_{(l, c) \in D_p} \log \frac{1}{1 + e^{- v' _ c v_l}} + \sum_{(l, c) \in D_n} \log \frac{1}{1 + e^{v' _ c v_l}} <br />
$$</p>
<ul>
<li>将订购的listing作为全局上下文: <ol>
<li>booking sessions 最后有订购</li>
<li>exploratory sessions</li>
</ol>
</li>
<li>对于 booking session, 认为最终订购的listing跟之前点击的每一个listing都有相关性,所以可以将它作为之前点击的每一个listing的全局上下文</li>
</ul>
<p>$$<br />
\arg\max_{\theta} \sum_{(l, c) \in D_p} \log \frac{1}{1 + e^{- v' _ c v_l}} + \sum_{(l, c) \in D_n} \log \frac{1}{1 + e^{v' _ c v_l}}  +  \sum_{l} \log \frac{1}{1 + e^{- v' _ b v_l}}<br />
$$</p>
<p>$( v_b )$ 是订购的listing</p>
<p>相当于增加一些正例!</p>
<ul>
<li>在搜索场景性,用户看到的和搜索的大多是同一个小市场/区域中的房屋,所以正例都是在同一个市场中的房屋对,而负例都是随机采样的,所以负例对大多不在同一个市场中。<br />
  这导致模型难以学到市场内的相似性差异,所以可以额外加入一些同一个市场中的负例对。</li>
</ul>
<p>$$<br />
\sum_{(l, m_n) \in D_{m_n}} \log \frac{1}{1 + e^{v' _ {m_n} v_l}}<br />
$$</p>
<p>$( D_{ m_n })$ 是采样自l同一个市场中的负例对。</p>
<ul>
<li>冷启动问题: 选出新房源地点附近10miles半径范围内,相同房屋类型,相同价格带的3个有embedding向量的其他房屋,用它们的均值代表新房源的向量</li>
<li>listing embedding检验: 向量维度32, session数量800M!</li>
<li>embedding的重点是为了学习房屋特点、结构、类型、观感etc,等难以直接提取的相似性。作者开发了一个评估工具:Similarity Exploration Tool</li>
<li>学习到的类型: 船屋、树屋、城堡、小木屋、海景房 <a href="https://youtu.be/1kJSAG91TrI">https://youtu.be/1kJSAG91TrI</a></li>
</ul>
<h3 id="user-type-listing-type-embeddings">User-type &amp; Listing-type Embeddings</h3>
<p>用用户的订购的序列作为session, 来学习跨market的相似性。这种跨market的相似性可以用来解决用户来到一个新的market的时候给他推荐的问题。<br />
但是这种方法由于数据稀疏会带来一下几个问题:</p>
<ol>
<li>大多数人的历史下单次数很少,甚至只有1个,没法学</li>
<li>listing的长尾特性,导致长尾的listing的向量学得不好</li>
<li>由于时间跨度长,原来假设的相邻两个listing是相似的假设并成立,因为用户的偏好、价格等因素以及发生了改变</li>
</ol>
<p>用 User-type &amp; Listing-type 而不是ID</p>
<p>上下文是 (User-type, Listing-type) 对, 购买的对是正例, 没有购买的对是负例, 被拒绝的对也是负例。</p>
<p>session是同一个用户的购买序列 user-type, listing-type 序列, s =(ut1, lt1, ..., utM, ltM)<br />
这样可以复用 word2vec 代码, 并在同一个空间投影, 让向量距离具有可比性!</p>
<h3 id="_2">试验</h3>
<ul>
<li>session构建: 按照登录用户ID, 将点击的listing id按照点击时间排序, 然后按照30分钟不活跃划分成多个session , session数量800M, listing数量 4.5M</li>
<li>过滤掉在listing页面停留少于30s的事件(认为是噪音), 保留至少2个listing的session</li>
<li>过采样 booked session, x5</li>
<li>每天定期训练配置:<ul>
<li>离线训练、评估、调参</li>
<li>滑动窗构建数据集, 数月的数据</li>
<li>每次都是重新开始训练(相同的随机数种子),随机初始化每一个向量; 发现比增量训练效果要好</li>
<li>每天都在变的向量对效果没有影响,因为最后使用的是余弦相似度作为特征</li>
<li>d=32, 主要是性能和相似度检索的性能之间的权衡</li>
<li>上下文窗口为5, 10次遍历整个训练集</li>
<li>修改了<a href="https://code.google.com/p/word2vec">word2vec</a></li>
<li>使用 MapReduce 训练: 300个mapper读数据, 1个reducer训练模型, 多线程训练 ?</li>
<li>Airflow2 <a href="http://airbnb.io/projects/airflow">http://airbnb.io/projects/airflow</a></li>
</ul>
</li>
<li>离线评估<ul>
<li>设最后一次点击的listing是A, 待排序的listing列表是: BCDEFG。。。,待排序的列表需要包含了最终订购的listing,<br />
  我们可以计算A和这些listing的余弦相似度, 然后根据相似度排序,从而得到订购的listing排序的rank, rank越小,说明越靠前。</li>
<li>这种排序得到的订购listing的rank,取决于两个重要因素,一是当前距离最后订购之间还有几次点击, 显然越接近订购行为,相关性越强;<br />
  二是embedding向量的好坏, 这正是要评估的东西。</li>
<li>为了评估两种embedding向量好坏,可以固定距离最终订购之间的点击次数,来比较排序, 排序越靠前, 说明学到的embedding向量跟最终的排序目标越接近。</li>
</ul>
</li>
</ul>
<p><img alt="离线评估结果图" src="/wiki/static/images/offline-eval-airbnb-kdd2018.png" /></p>
<ul>
<li>
<p>相似listing推荐</p>
<ul>
<li>现有的方法是在给定的listing附近,根据是否可定购、价格范围、房屋类型筛选出候选集,然后调用搜索排序模块</li>
<li>从同一个market中, 在相同的日期内可订购的房屋中, 利用embedding向量直接找K近邻, 用余弦相似度度量距离</li>
<li>CTR 提升了21%</li>
</ul>
</li>
<li>
<p>实时个性化 </p>
<ul>
<li>排序模型: <ul>
<li>标签: $( y_i \in \{ 0, 0.01, 0.25, 1, -0.4 \} )$ 分别代表,只曝光,曝光后只有点击, 曝光后用户联系了但是没订购, 1订购, -0.4房东拒绝了。</li>
<li>特征: listing features, user features, query features and cross-features</li>
<li>曝光后用一周的观测时间获得label, 只保留那些曝光列表中有订购的房屋的数据。</li>
<li>利用<a href="https://github.com/yarny/gbdt">GBDT</a>进行 pairwise regression, lambda rank损失, NDCG metric。</li>
<li>Listing Embedding Features: <ul>
<li>对于每个用户ID, 用Kafka收集用户近两周的房屋id集合<ol>
<li>Hc 近两周点击过的listing id</li>
<li>Hlc 点击过且页面停留时间超过60s的listing id</li>
<li>Hs 用户跳过的曝光靠前的listing id</li>
<li>Hw 用户近两周加到心愿单的listing id</li>
<li>Hi 用户近两周咨询过的listing id</li>
<li>Hb 用户近两周订购过的listing id</li>
</ol>
</li>
<li>将上述每一个集合进一步分成同market的子集, 例如: Hc 里面有 New York 和 Los Angeles两个市场,那么就会分成两个子集 Hc(NY), Hc(LA)</li>
<li>以EmbClickSim为例,说明这个特征的构造过程:<ol>
<li>先计算每一个market的embedding中心, 也就是按照Market对 listing id的vector做average Pooling</li>
<li>计算候选的listing的向量与每一个中心的相似度(距离), 得到多个距离,然后取相似度的最大值(最小距离), max pooling</li>
</ol>
</li>
<li>EmbLastLongClickSim 是从Hlc中找到最近点击的listing id,计算的相似度,最后一个影响大</li>
<li>UserTypeListingTypeSim 直接拿type的embedding向量计算的余弦相似度</li>
</ul>
</li>
<li>特征单因素分析,固定其他特征,改变单个特征,分析单个特征变化对排序分数影响, (跟我的想法一模一样)</li>
</ul>
</li>
</ul>
</li>
<li>
<p>NDCU(Discounted Cumulative Utility)提升 2.27%, 指标就不列了</p>
<ul>
<li>NDCU 相当于用y作为Gain, 计算的NDCG, 而不是用 $(2^r - 1)$ 作为Gain ?</li>
</ul>
</li>
</ul>
<p><img alt="embedding 特征" src="/wiki/static/images/embedding-feature-airbnb-kdd2018.png" />          <br />
<img alt="emb-click-sim" src="/wiki/static/images/emb-click-sim.png" /></p>
<p><a href="https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e">https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e</a></p>
<h2 id="_3">问题</h2>
<ol>
<li>wor2vec 如何嵌入到MapReduce中?怎么实现?</li>
<li>NDCU ?</li>
</ol>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-12-23 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '【KDD2018-Airbnb】Real-time Personalization using Embeddings for Search Ranking at Airbnb',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>