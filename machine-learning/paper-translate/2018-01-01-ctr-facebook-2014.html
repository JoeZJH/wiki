<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>Facebook 预测广告点击率的实践经验 - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning-paper-translate">paper-translate</a>&nbsp;»&nbsp;Facebook 预测广告点击率的实践经验</div>
</div>
<div class="clearfix"></div>
<div id="title">Facebook 预测广告点击率的实践经验</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#facebook">Facebook 预测广告点击率的实践经验</a><ul>
<li><a href="#_1">摘要</a></li>
<li><a href="#_2">引言</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="facebook">Facebook 预测广告点击率的实践经验</h1>
<h2 id="_1">摘要</h2>
<p>在线广告允许广告客户只为可以测量的用户反应出价和支付，比如点击广告。 所以，在线广告系统中点击预测系统是大多数在线应用的核心。在Facebook上，每天活跃用户超过7.5亿，活跃广告客户有100多万，点击率预估在Facebook广告中是一个具有挑战性的机器学习任务。本文介绍了一个结合决策树与逻辑回归的模型，它超越了其中任何一个单独的方法，效果提升了超过3％，这个提升对整个广告系统的效果有显着的影响。然后我们探索一些基本参数如何影响我们系统的最终预测性能。我们发现，最关键的是要有正确的特征： 那些有关用户历史信息或广告领域的其他类型的特征。一旦我们有正确的特征和正确的模型（决策树加逻辑回归），其他因素影响很小（在大规模的情况下，虽然很小的改善也是重要的）。选择最佳处理数据新鲜度，学习速率和数据采样只稍微提高了一点点，远不及添加一个高价值的特征，或选择正确的模型</p>
<h2 id="_2">引言</h2>
<p>数字广告是一个价值数十亿美元的行业并且每年大幅增长。在大多数在线广告平台，广告的分配是动态的，基于用户观察后的反馈为用户的兴趣量身打造的。机器学习在预估候选广告给用户的效果中起着核心作用，并增加了市场效率。<br />
2007年，Varian [11]和Edelman[4]等人的开创性论文描述了由Google和Yahoo的出价(bid)和每次点击付费的先驱工作! 同年，微软也是在此基础上基于竞价模型构建一个赞助搜索市场[9]。 广告拍卖的效率取决于 对点击预测的准确度和校准。 该 点击预测系统需要具有鲁棒性和自适应性 能够从大量的数据中学习。 目标 本文的目的是分享来自实验的见解 考虑到这些要求并执行 对现实世界的数据。 在赞助搜索广告中，用户查询用于 检索候选广告，显式或隐式地 匹配查询。 在Facebook上，广告没有关联 用查询，而是指定人口和兴趣 定位。 因此，广告的数量 有资格在用户访问Facebook时可以显示 大于赞助搜索。 为了处理大量的候选广告 请求，每当用户触发广告请求 访问Facebook，我们将首先建立一个级联的分类器 增加计算成本。 在本文中，我们重点介绍 级联分类器的末级点击预测模型， 那就是为最终集合产生预测的模型 的候选广告。 我们发现一个结合决策树的混合模型 逻辑回归优于这两种方法之一 靠自己超过3％。 这种改善有重大意义 影响整个系统的性能。 一些 基本参数影响最终的预测效果 - 我们的系统。 如预期的那样最重要的事情 是要有正确的功能： 形成关于用户或广告主宰其他类型的功能， 功能。 一旦我们有正确的功能和正确的模式 （决策树加逻辑回归），其他因素发挥作用 小角色（尽管小小的改进很重要 规模）。 为数据新鲜度选择最佳处理方式， 学习率模式和数据采样改善模型 稍微，虽然比添加高价值功能少得多， 或者选择合适的模型开始。 我们首先概述了我们在Sec- 在第3部分我们评估不同的概率线性<br />
第2页<br />
分类器和多种在线学习算法。 在合约 线性分类文本我们继续评估影响 功能转换和数据新鲜度。 受到了启发 吸取的实际经验教训，特别是数据新鲜度 和在线学习，我们提出了一个模型架构， 企业在线学习层，而公平地生产 紧凑型号。 第4节描述了一个关键组件 为在线学习层，在线木匠，一个 可以生成实况的实验性基础设施 实时训练数据流。 最后，我们提出交易记忆和准确性的方法 计算时间，并应付大量的培训 数据。 在第五部分中，我们描述了一些实用的方法， 包含大规模应用程序的时间和延迟 在第6节我们深入到了训练数据之间的权衡 数量和准确性。 2.实验安装 为了达到严格和可控的实验，我们 通过选择任意一周准备训练数据 在2013年第四季度。为了保持不变 培训和测试数据在不同的条件下， 削减了与观察到的类似的训练数据 线上。 我们把存储的数据分成训练和 测试并使用它们来模拟在线数据， 在线培训和预测。 相同的培训/测试数据 被用作本文所有实验的测试平台。 评估指标：因为我们最关心的 这些因素对机器学习模型的影响， 我们直接使用预测的准确性而不是度量 与利润和收入有关。 在这项工作中，我们使用Normal- 熵（NE）和校准作为我们的主要评估 度量。 归一化熵更准确， 熵相当于每次印象的平均对数损失 除以每次印象的平均对数损失 如果一个模型预测了背景点击率 （CTR）为每个印象。 换句话说， 由背景的熵归一化的对数对数损失 CTR。 背景点击率是平均经验点击率 的训练数据集。 这可能会更多的描述 - 将这个度量称为归一化对数（Normalized Logarithmic） 失利。 值越低，预测越好 由模型制作。 这个正常化的原因是 背景CTR越接近0或1， 更容易实现更好的日志丢失。 除以en- 背景CTR的回归使得NE不敏感 背景点击率。 假设一个给定的训练数据集 N个具有标签的示例y i 2 {1，+ 1}和估计的概率 - 点击的能力 我在哪里我= 1，2，... N。 平均经验值 CTR作为p NE = 1 N P n 我= 1 （ 1 + y 我 2 log（p i ）+ 1y i 2 日志（1 p i ）） （p⇤log（p）+（1 p）⇤log（1 P）） （1） NE基本上是计算相对信息的一个组成部分， 增益（RIG）和RIG = 1 NE 图1：混合模型结构 输入功能 通过增强的决策树进行转换。 每个单独的树的输出被视为一个 将分类输入特征映射到稀疏线性分类器。 提升的决策树被证明是非常强大的 功能转换。 校准是平均估计点击率和 经验性点击率 换句话说，这是数字的比例 预期点击次数达到实际观察到的点击次数。 校准是一个非常重要的指标，因为准确和 经过精心校准的CTR预测对成功至关重要 在线竞价和拍卖。 校准不同 从1开始，模型越好。 我们只报告校准 在不重要的实验中。 请注意，ROC区域（AUC）也是相当不错的 不考虑排名质量的度量 校准。 在现实的环境中，我们预计， 词典是准确的，而不是仅仅得到最佳的选择。 错误的排列顺序，以避免潜在的不足交付或过度使用， 交货。 NE衡量预测的好处， 明确地反映了校准。 例如，如果一个模型over- 预测2倍，我们应用全球乘数0.5来解决 校准后，对应的NE也会有所改善 即使AUC保持不变。 详见[12] 研究这些指标。 3.预测模型结构 在本节中，我们提出一个混合模型结构： 提升的决策树和概率 - 抽动稀疏线性分类器，如图1所示。在Sec- 我们显示决策树是非常强大的输入 功能转换，这大大增加了ac- 概率线性分类器的精度。 在3.2节我们 展示如何更新鲜的训练数据导致更准确的预处理， 新词语。 这激发了使用在线学习的想法 方法来训练线性分类器。 在3.3节中， 削减了两个家庭的在线学习变量 概率线性分类器。 我们评估的在线学习计划是基于<br />
第3页<br />
随机梯度下降（SGD）算法[2]适用于 稀疏线性分类器。 经过功能转换后， 广告印象是以结构化向量x =给出的 （e i 1 ，...，e i n ）其中e i是第i个单位矢量，i 1 ，...，i n 是n个分类输入特征的值。 在里面 训练阶段，我们也假设我们得到了一个二进制 指示点击或不点击的标签y 2 {+1,1}。 给定一个标记的广告印象（x，y），让我们表示线性 活动权重的组合 s（y，x，w）= y·w T x = y ñ X J = 1 w j，i j ， （2） 其中w是线性点击分数的权重向量。 在最先进的贝叶斯在线学习计划中 概率回归（BOPR）描述[7]的可能性和 事先给出 p（y | x，w）= ✓s（y，x，w）◆， p（w）= ñ ÿ k = 1时 N（W·K;μK，2 k ）， （t）是标准的累积密度函数 正态分布和N（t）是密度函数 标准正态分布。 在线培训已经实现 通过期望传播与时刻匹配。 最终的模型由均值和方差组成 权重向量的近似后验分布 W上。 BOPR算法中的推理是计算 p（w | y，x）并将其投影到最接近因子分解的Gaus- （w）的sian近似。 因此，更新算法 可以单独用所有的更新方程来表示 意义和方差的非零组件x（见[7]）： μI J μI J + Y· 2 我 j ^·v✓ s（y，x，μ） ^ ◆， （3） 2 我 j 2 我 j ·“1 2 我 j ^ 2 ·w✓ s（y，x，μ） ^ ◆＃， （4） ^ 2 = 2 + ñ X J = 1 2 我 j 。 （5） 这里，校正函数v和w由v（t）：=给出 N（t）/（t）和w（t）：= v（t）·[v（t）+ t]。 这个推断可以 被视为信念向量μ和的SGD方案。 我们将BOPR与可能性函数的SGD进行比较 p（y | x，w）= sigmoid（s（y，x，w））， 其中sigmoid（t）= exp（t）/（1 + exp（t））。 由此产生的al- 算法通常被称为Logistic回归（LR）。 推断 - 在这个模型中计算对数的导数， 可能性和步行每个坐标依赖步长 这个梯度的方向： w i j 瓦特 I J + Y·⌘I J·G（S（Y，X，W））， （6） 其中g是所有非零com- 并且由g（s）给出：= [y（y + 1）/ 2 y·sigmoid（s）]。 请注意，（3）可以被看作是一个每坐标梯度de- 香味等（6）上的平均矢量μ，其中步长⌘I J 是由信念不确定性自动控制的。 在 3.3小节将介绍各种步长函数⌘ 并与BOPR进行比较。 上述的基于SGD的LR和BOPR都是流式的 学习者一个接一个地适应训练数据。 3.1决策树特征转换 有两种简单的方法来转换输入功能 的线性分类器，以提高其准确性。 对于 连续的功能，学习非线性的简单技巧 转化是为了将这个特征和待处理的垃圾箱 dex作为一个分类特征。 线性分类器有效 学习特征的分段恒定非线性映射。 学习有用的bin边界是很重要的，并且有 许多信息最大限度地做到这一点。 第二个简单而有效的转换包括 构建元组输入功能。 对于分类特征， 蛮力方法包括采取笛卡尔产品， uct，即创建一个新的分类特征 作为原始特征的所有可能值的值。 不 所有的组合都是有用的，而那些不是可以的 剪掉了。 如果输入功能是连续的，可以这样做 联合装箱，例如使用kd树。 我们发现，推动决策树是一个强大的，非常 便捷的方式来实现非线性和元组transfor- 我们刚刚描述的那种。 我们对待每个指标， 个人树作为一个分类特征，作为值 叶子的索引最终落入。我们使用1- 这种类型的特征的-K编码。 例如，考虑 图1中的增强树模型有2个子树，其中 第一个子树有3个叶子和第二个叶子。 如果 实例结束于第一个子树中的叶子2和叶子1中 第二个子树，将整体输入到线性分类器中 是二进制向量[0,1,0,1,0]，其中前3个条目 对应第一个子树的叶子，最后2个 那些第二个子树。 推动决策树我们 使用遵循梯度增压机（GBM）[5]，其中 使用经典的L 2 -TreeBoost算法。 在每个学习 - 迭代，创建一个新的树来模拟残差 以前的树木。 我们可以理解提升的决策树 作为一个监督的特征编码 将实值向量转换为紧凑二进制值 向量。 从根节点到叶节点的遍历表示 某些特征的规则。 拟合一个线性分类器 二元向量本质上是学习权重的集合 规则。 提升的决策树以批处理方式进行培训。 我们进行实验来显示包括树的效果 作为线性模型的输入。 在这个实验中 我们比较两个logistic回归模型， 变换和其他与平原（非转换） 特征。 我们也只使用一个提升的决策树模型 比较。 表1显示了结果。 树状特征转换有助于减少标准化的En- 相对于标准化来说超过3.4％ 没有树变换的模型的熵。 这是一个 非常显着的相对改善。 作为参考， ical feature engineering experiment will shave off夫妇 几十％的相对NE。 有趣的是看到<br />
第4页<br />
表1：Logistic回归（LR） 锡永树（树）做出强有力的组合。 我们 评估他们的归一化熵（NE） 相对于只有树的模型。 模型结构NE（仅限于树） LR +树木 96.58％ 只有LR 99.43％ 树只 100％ （参考） 图2：预测精度作为一个函数 训练和测试之间的延迟以天为单位。 Accu- 活动表示为归一化熵相对于 最坏的结果，得到的树木模型 推迟6天。 孤立使用的LR和Tree模型具有相似性， rable预测准确性（LR是好一点），但它是 他们的组合产生了一个精确的飞跃。 中的收益 预测准确性显着; 供大家参考 特征工程实验只能减少 归一化的熵由百分之几分之一。 3.2数据新鲜度 点击预测系统通常部署在动态环境中， 数据分布随时间变化的数据。 我们 研究训练数据新鲜度对预测每个人的预测效果， formance。 要做到这一点，我们在一个特定的日子里训练模型 并在连续的几天进行测试。 我们运行这些实验 对于一个推动的决策树模型和一个逻辑的 具有树变换的输入特征的回归模型。 在这个实验中，我们训练一天的数据，并进行评估 连续六天计算归一化 每个熵。 结果如图2所示。 预测精度明显降低，因为两种模式 训练和测试集之间的延迟增加。 对于这两个mod- 可以看出NE可以减少近似值 从每周的培训到每天的培训只有1％。 这些发现表明，每天都值得重新培训 基础。 一种选择是重复日常工作 可能会批量培训模型。 所需要的时间 再培训推动的决策树根据不同的因素而有所不同 如培训的例子数量，树木的数量， 每棵树上的叶子数量，cpu，内存等。可能需要 超过24小时，建立一个数百人的助推模型 数以亿计的实例中， GLE核心CPU。 在实际情况下，可以完成培训 在几个小时内通过多核心的充分并发 整体拥有大量内存的机器 训练集。 在下一节我们考虑一个替代方案。 推动决策树可以每天或每个cou- 几天的时间，但线性分类器可以在近处训练 通过使用一些在线学习的风味实时。 3.3在线线性分类器 为了最大限度地提高数据的新鲜度，一种选择是训练 在线分类器，即直接作为标签 广告印象到达。 在即将到来的第四部分中， 扫描一个可以实时生成的基础设施 训练数据。 在本节中，我们将评估几种方法 为基于SGD的在线学习设置学习率， gistic回归。 然后，我们将最好的变体与在线比较 学习BOPR模型。 就（6）而言，我们探讨以下选择： 1.每坐标学习率： 迭代t的ture被设置为 ⌘t ，i = ↵ + qP t j = 1 r 2 J，I 。 是两个可调参数（在[8]中提出）。 2.权重平方根学习率： ⌘t ，i = ↵ pn t，i ， 其中n t，i是具有特征的总训练实例 我直到迭代t。 3.重量学习率： ⌘t ，i = ↵ 不 ，我 。 4.全球学习率： ⌘t ，i = ↵ PT。 5.不断学习率： ⌘t ，i =↵。 前三个方案分别设置学习率 特征。 最后两个使用相同的速度为所有功能。 所有 可调参数通过网格搜索（optima）进行优化 详见表2.） 我们将学习率下降0.00001连续 学习。 我们用相同的数据训练和测试LR模型 以上学习率计划。 实验结果是 如图3所示。 从以上结果可以看出，SGD以每坐标学习为主 速率达到最好的预测精度，用NE al- 比使用每重量学习率低5％<br />
第5页<br />
表2：学习速率参数 学习率模式 参数 每坐标 0.1 = 0.1，= 1.0 重量平方根 = 0.01 每重量 = 0.01 全球 = 0.01 不变 0.000 = 0.0005 图3：不同学习的实验结果 LR新加坡元汇率。 X轴cor- 回应不同的学习率计划。 我们 在左侧绘制标定y- 轴，而归一化的熵则用 右边的第二y轴。 表现最差。 这个结果是符合结论的， sion [8]。 新元与重量平方根和恒定 学习率达到相似和略差的NE。 该 其他两种方案比以前差很多 版本。 全球学习率主要由于失败 每个功能上的训练实例数量不平衡。 由于每个培训实例可能包含不同的功能， 一些受欢迎的功能，接受更多的培训， 立场比别人。 根据全球学习率计划， 对于具有较少实例的特征的学习率， 折痕太快，并防止收敛到最佳状态 重量。 虽然每重量学习费率计划ad- 打扮这个问题，它仍然失败，因为它减少了 所有功能的学习速度太快。 培训终止 模型收敛到次优点的地方太早了。 这就解释了为什么这个方案的性能最差 在所有的选择之中。 有意思的是BOPR更新方程 （3）平均数与每坐标学习最相似 SGD的LR版本。 有效的学习率 BOPR是针对每个坐标而定的，取决于 与每个个体相关的体重的后验方差 协调，以及给予什么标签的“惊喜” 模型会预测[7]。 我们进行了一个实验， 通过每个坐标SGD和BOPR训练LR的形式。 我们训练LR和BOPR模型 排序器” Online'Joiner” 培训师” 功能{x} 点击{y} 楷模 {x，y} 广告 图4：在线学习数据/模型流程 数据并评估下一次的预测性能 天。 结果如表3所示。 表3：每坐标在线LR与BOPR 模型类型 NE（相对于LR） LR 100％ （参考） BOPR 99.82％ 也许正如人们所期望的那样，鉴于质量的相似性 更新公式，BOPR和LR用SGD进行培训 每坐标学习率有非常相似的预测， 无论是NE还是校准都可以提高性能 （未在表格中显示）。 LR比BOPR的一个优点是模型的大小 是一半，因为只有一个相关的权重 稀疏特征值，而不是均值和方差。 去 等待实施，更小的模型大小可能 导致更好的缓存局部性，从而更快的缓存查找。 在 在预测时间计算费用的条款，LR 模型只需要一个内部产品的功能vec- tor和权重矢量，而BOPR模型需要两个 方差向量和均值向量的内积 与特征向量。 BOPR比LR更重要的一个优点是， 贝叶斯公式，它提供了一个完整的预测分布 - 点击概率。 这可以用来com- 预测分布的百分位数，可以 用于探索/开发学习计划[3]。 4.在线数据连接器 前一节确定了更新的训练数据 导致预测准确度提高。 它还提出了一个 线性分类器层的简单模型架构 在线培训。 本部分介绍了一个实验系统， 用于训练线性分类器的实时训练数据， 通过在线学习更加困难。 我们将这个系统称为 “在线木匠”，因为它的关键操作是加入 标签（点击/不点击）到培训输入（广告印象）中 一个在线的方式。 类似的基础设施用于流 例如在Google广告系统[1]中学习。 在线木匠输出实时训练数据流 到一个名为Scribe的基础设施[10]。 而积极的<br />
第6页<br />
标签（点击）是明确的，没有这样的事情 用户可以按“不点击”按钮。 为此，一个 印象被认为是否定否定点击标签 用户在固定之后没有点击广告，并且充分地 看到广告后很长一段时间。 的长度 等待时间窗口需要仔细调整。 使用等待时间过长会延迟实时训练， 增加数据并增加分配给缓存的内存 等待点击信号的印象。 太短了 时间窗口导致一些点击丢失，因为 相应的印象可能已经被刷新， 作为未点击的贝壳。 这对“点击覆盖”产生了负面影响 所有点击成功加入展示的比例。 因此，网上木匠系统必须取得平衡 新近度和点击率之间。 没有完整的点击覆盖意味着实时培训 - 一套将是有偏见的：经验性的点击率是有点 低于事实的真相。 这是因为一小部分 的标记为未点击的展示次数将会是la- 如果等待时间足够长，可以点击。 然而在实践中，我们发现很容易减少这种情况 对等待窗口百分比的小数点偏差 大小，导致可管理的内存要求。 在 此外，这个小偏差可以测量和纠正。 可以找到更多关于窗口大小和效率的研究 在6点钟]。 在线木匠被设计来执行分布式 流到流加入广告展示和广告点击uti- 将请求ID作为连接的主要组件 谓词。 每次用户每次生成一个请求ID时， 在Facebook上形成一个触发刷新的动作 他们所接触到的内容。 原理图数据和模型 显示了在线加工者随后在线学习的流程 如图4所示。初始数据流是当用户产生的 访问Facebook并向排名提出请求， 没有广告 广告被传回给用户的设备 并行使用每个广告和相关的功能 排名印象被添加到印象流中。 如果用户选择点击广告，该点击将被添加 到点击流。 实现流到流的连接 系统利用一个HashQueue组成一个First-In- 先出队列作为缓冲窗口和快速的散列图 随机访问标签展示次数 一个HashQueue 在键值对上有三种操作：排队， 出列和查找。 例如，要排队一个项目，我们 将项目添加到队列的前面并在中创建一个键 散列映射，其值指向队列的项目。 只有完整的加入窗口过期后，标签才会显示 印象被发射到训练流。 如果没有点击 它将作为负面标记的例子发射出去。 在这个实验设置中，教练员不断学习 从培训流程中发布新款车型， 对于Ranker而言。 这最终形成一个严密的封闭 循环的机器学习模型的变化， 可以捕获分布或模型性能， 了解到，并在短期内继续纠正。 实验一个重要的考虑因素 实时训练数据生成系统是需要的 建立防止异常的保护机制 腐败在线学习系统。 让我们来简单介绍一下 例。 如果点击流由于某些原因而变得陈旧 数据基础设施问题，网上木匠将产生train- 这些数据具有非常小的甚至为零的经验性点击率。 由此，实时教练将开始 错误地预测非常低，或者接近零概率 单击。 广告的预期价值自然取决于 估计的点击概率，以及一个结果 错误地预测非常低的点击率是系统可能 展示广告展示次数减少。 异常检测 - 重刑机制可以在这里帮助。 例如， 从网上木匠matically断开在线教练 如果实时训练数据分布突然改变。 5.包含内存和延迟 5.1增强树的数量 模型中的树越多，所需的时间就越长 做一个预测。 在这个部分，我们研究了这个效果 估计精度的推动树数量。 我们改变树的数量从1到2 000，并训练 模型在一天的数据，并测试预测per- 在第二天的表演。 我们只限于此 每棵树上有12片叶子。 与之前的实验类似， 我们使用归一化熵作为评估指标。 该 实验结果如图5所示。 图5：增强次数的实验结果 树木。 不同系列对应不同的子系列 楷模。 x轴是助推树的数量。 Y轴是归一化的熵。 热带植物减少，因为我们增加了增加树木的数量。 然而，增加树木的收益会减少重新生长， 转。 NE的改进几乎都来自前500名 树木。 最后一千棵树使NE降低不到0.1％。 此外，我们看到子模型的归一化熵 2棵树开始退化后，1000棵树。 之所以这样做， 现象是过度配合。 由于子模型的训练数据 2比子模型0和1小4倍。 5.2提升功能重要性 特征计数是另一个模型特征， 在估算精度和计算之间取舍， 性能。 为了更好地理解功能的效果 算上我们首先将特征重要性应用于每个特征。 为了衡量我们使用的功能的重要性 统计促进特征重要性，<br />
第7页<br />
确定归因于特征的累计损失减少量。 在每个树节点结构中，选择一个最佳特征 分割以最大化平方误差减少。 由于一个功能， 可以用于多种树木，（增强特征 重要性）为每个功能是通过求和来确定的 所有树木的特定特征的总减少量。 通常情况下，少数特征贡献了主 - 而其余特征具有解释性权力 只有边际贡献。 我们看到这种模式 当绘制功能的数量与他们的cumu- 图6中的特征重要性。 图6：提升功能重要性 X轴cor- 响应功能的数量。 我们画功能 在左侧小学对数的重要性 y轴，而累积特征的重要性是 与右边的副y轴一起显示。 从以上的结果可以看出，前十名的特点是 负责总功能重要性的大约一半， 而最近的300个功能贡献不到1％的功能 重要性。 基于这个发现，我们进一步做实验 只保留了前10,20,50,100和200个功能， 并评估表现如何影响。 的结果 实验如图7所示。从图中我们可以看出 可以看到归一化的熵有类似的递减 返回属性，因为我们包含更多功能。 下面我们将对这个实用性进行一些研究 的历史和背景特征。 由于数据sen- 敏度的性质和公司政策，我们不能够 揭示在我们实际使用的功能细节。有些EX- 充足的上下文特征可以是一天的当地时间，天 周等历史特征可以是累计数 的点击广告，等等。 5.3历史特点 在升压模式中使用的功能可分为 分为两种类型：上下文特征和历史特点。 语境功能的价值完全取决于CUR- 租有关的上下文信息，其中广告是 示出的，诸如由用户或CUR-所使用的设备 租页面，用户上。相反，历史 功能依赖于广告或用户以前的互动， 例如，通过广告的点击率在上周，或 平均点击通过用户的速度。 图7：结果与顶部fea-推进模型 功能。我们利用校准在左侧革命制度党 玛丽y轴，虽然示出归一化的熵 与右手侧次级y轴。 在这一部分，我们研究如何系统的性能 取决于两个类型的特征。首先，我们检查 这两种类型的特点的相对重要性。我们这样做是通过 按重要性排序的所有功能，然后计算出per- 在第k个重要特征历史特色centage。 结果在图8中由该结果所示，我们可以看到 图8：结果历史风貌百分比。 X轴对应于特征数。Y轴 给的历史特点在顶部K-百分比 重要特征。 该历史风貌提供了相当多的explana- 保守党功率比上下文特征。排名前10的特征或 - 按重要性dered都是历史特色。之间 排名前20位的特点，也有只有2上下文特征，尽管 历史特征占据的特征大致75％在 此数据集。为了更好地理解的比较值 从各类型合计，我们班列车2个助推功能 荷兰国际集团车型只有上下文特征，只有历史 功能，那么这两个型号的完整比较 模型的所有功能。结果示于表4。 从表中，我们可以再次确认，在他的 - 汇总 torical功能发挥出比上下文特征发挥更大的作用。<br />
第8页<br />
表4：具有不同类型的推进fea-模型 功能 特征NE的类型（相对于语境） 所有 95.65％ 历史的 96.32％ 上下文 100％ （参考） 没有只上下文特征，我们衡量4.5％的损失 预测精度。相反，没有上下文 功能，我们遭受的预测精度小于1％的损失。 应该注意到，上下文功能都非常的IM portant处理冷启动问题。对于新用户和 广告，上下文特征是必不可少的一种合理 点击率预测。 在下一步，我们评估与他的 - 只有在训练的模型 在连续torical功能或上下文特征 周来测试数据新鲜度的特征依赖。 该 结果示于图9。 图9：结果datafreshness用于不同类型 的功能。X轴是而y轴上的评估日期 是归一化熵。 从图中我们可以看到，与情境模型 功能更依赖比历史数据新鲜度 特征。 这是与我们的直觉线，因为历史fea- 功能形容长期积累的用户行为， 比上下文特征更加稳定。 6.海量训练数据期应对 Facebook的广告印象数据的一整天可以包含 大量实例。请注意，我们不能 透露实际数字，因为它是保密的。但小 一天的有价值的数据的部分可以有几百 数以百万计的实例。用于控制的一种常用技术 培训成本降低了培训的数据量。 在这一节中，我们评估两种技术下采样 数据，均匀子采样和负向下采样。 在 每次我们训练了一套增强型树模型与600棵树情况 并同时使用校准和标准化评估这些 熵。 6.1统一的二次抽样 培训行统一欠采样是一个诱人的AP- proach减少数据量，因为它是既容易 实现并且可以使用所产生的模型与 - 出来的二次抽样训练数据和修改都 非二次抽样的测试数据。在这一部分，我们评估了一组 大约成倍增加二次采样率。 对于 每一个速度，我们培养了增强型树模型，在这个采样 率从基部数据集。我们改变二次采样率 在{0.001,0.01，0.1％，0.5％，1}。 对数据量的结果在图10中它是在示 图10：数据量试验的结果。 该 X轴对应于训练实例数。 我们利用校准在左侧主 y轴，而归一化的熵被示为具有 右手侧次级y轴。 与我们的直觉线更多的数据带来更好的per- formance。此外，数据表明体积dimin- ishing在预测准确度方面的回报。只用 数据的10％，则归一化的熵仅1％reduc- 重刑在相对于整个训练数据集的性能。 在这个采样率校准没有显示性能 减少。 6.2负下采样 一流的失衡已经研究了许多研究人员和 已被证明对perfor-显著影响 学习模式 - 曼斯。在这一部分中，我们调查 使用负向下采样的解决类不平衡 问题。 我们经验与不同的负试验 下采样率来测试的预测精度 学习模型。我们而变化{0.1，0.01，0.001，0.0001}的速率。 实验结果示于图11。 从结果中我们可以看到，负下降SAM- pling率对的性能显著影响 训练模型。最佳的性能与neg-实现 ative下行采样率设置为0.025。 6.3型号重新校准 负采样可以加快培养和提高 模型的性能。需要注意的是，如果一个模型在数据训练<br />
第9页<br />
图11：阴性实验结果比较下降 采样。X轴对应于不同nega- 略去下行采样率。我们利用校准的 左手侧主y轴，而归一化的 熵被示出具有右手侧次级 y轴。 设置有负下采样，也校准预 文辞的采样空间。例如，如果aver- 取样前年龄的点击率是0.1％，我们做一个负0.01 下采样，经验CTR将成为约10％。 我们需要重新校准的实际流量实验模型 并取回与q中的0.1％的预测= p P +（1P）/ w的 其中p是下采样空间和瓦特的预测 负采样率。 7.讨论 我们从实验 - 提出了一些实用的经验教训 荷兰国际集团与Facebook的广告数据。这一直激励着一个有前途的 对于点击预测混合模型架构。 •数据新鲜度的问题。值得一至少再培训 日常。在本文中，我们更进一步讨论 各种在线学习方案。我们还提出 基础设施，使生成的实时培训 数据。 •转型实值输入功能与提升 决策树显著提高预测AC- 概率线性分类的curacy。 这激励着 该串接升压混合模型架构 决策树和稀疏线性分类。 •最优惠的在线学习方法：LR每个坐标 学习率，这最终是类似的在per- 与BOPR formance，并执行胜过一切 正在研究其他LR SGD方案。（表4，图12） 我们已经描述的技巧来维持内存和延迟CON组 tained在大规模机器学习应用 •我们已经提出的数量之间的权衡 提高决策树和准确性。有利的是， 保持树木小，以保持计算的数量 记忆包含。 •提振决策树给做的一种便捷方式 通过功能重要手段特征选择。 一 可积极地减少的活性特征的数量 而只有适度的伤害预测精度。 •我们分析了使用历史fea-的影响 功能与上下文特征的组合。对于广告 和用户提供的历史，这些功能提供了优于 预测性能比背景特征。 最后，我们已经讨论了欠采样培训方式 数据，都均匀地而且更有趣在偏置 办法只有负面例子子采样。</p>
</div>
<div id="income">
    <img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" />

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div id="content-footer">created in <span class="create-date date"> 2017-01-26 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'Facebook 预测广告点击率的实践经验',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>