<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>Graph Convolutional Neural Networks for Web-Scale Recommender Systems - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;<a href="/wiki/#-gnn">gnn</a>&nbsp;»&nbsp;Graph Convolutional Neural Networks for Web-Scale Recommender Systems</div>
</div>
<div class="clearfix"></div>
<div id="title">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">简介</a><ul>
<li><a href="#_2">解决的问题</a></li>
</ul>
</li>
<li><a href="#faq">FAQ</a><ul>
<li><a href="#_3">模型的主要思路是什么</a></li>
<li><a href="#_4">主要贡献点是什么</a></li>
<li><a href="#_5">数据量有多大</a></li>
<li><a href="#_6">图是如何构造的</a></li>
<li><a href="#_7">节点的特征是如何构造的</a></li>
<li><a href="#_8">评估方式有哪些</a></li>
<li><a href="#_9">向量的应用</a></li>
<li><a href="#_10">文章做了哪些关键事情提升了扩展性</a></li>
<li><a href="#_11">为什么卷积的时候要先做一层变换，而不是直接聚合</a></li>
<li><a href="#_12">为什么聚合之后还要再来一层变换</a></li>
<li><a href="#_13">为什么不降顶点自己的向量在第一层融合的时候就融合进去</a></li>
<li><a href="#concatavg">怎么理解用concat比avg性能提升较大</a></li>
<li><a href="#_14">为什么最后还要归一化</a></li>
<li><a href="#_15">卷积时的采样是如何进行的</a></li>
<li><a href="#node">每个node的采样权重是如何构造</a></li>
<li><a href="#pooling">Pooling的重要性加权是如何做的</a></li>
<li><a href="#_16">卷积的参数有哪些</a></li>
<li><a href="#_17">训练的监督信号？</a></li>
<li><a href="#_18">训练过程如何</a></li>
<li><a href="#producer-consumer-minibatch-construction">Producer-consumer minibatch construction是什么</a></li>
<li><a href="#_19">负采样的优化</a></li>
<li><a href="#curriculum-training">Curriculum training 是怎么做的</a></li>
<li><a href="#naivegpu">为什么naive的方法无法最大限度利用GPU</a></li>
<li><a href="#gpu">为什么文章的方法可以最大限度利用GPU</a></li>
<li><a href="#mapreduce">MapReduce推断是如何做的</a></li>
<li><a href="#naive">naive的方法为什么会有重复计算</a></li>
<li><a href="#weak-and">Weak And 是什么</a></li>
<li><a href="#_20">试验的对比对象有哪些</a></li>
<li><a href="#_21">相比内容的方法，本文的方法多了什么额外的信息</a></li>
<li><a href="#_22">计算资源</a></li>
<li><a href="#_23">离线评估指标</a></li>
<li><a href="#item">查看随机两个item的余弦相似度分布有什么用</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="_1">简介</h1>
<ul>
<li>本文是GraphSAGE的落地版本</li>
</ul>
<h2 id="_2">解决的问题</h2>
<ul>
<li>解决i2i推荐的问题</li>
<li>一个pin有图像，文字。传统的方式就是从图片和文字中抽取特征（VGG16，word2vec），然后计算item的相似度</li>
<li>上述的问题：用户会收藏相似的pin到一个board中，这个信息比较有价值，但是上述方法没有利用到</li>
<li>本文的解决思路：将pin和board关系表示成一个二分图，将这种收藏关系用图结构来表达，那么只要有个模型能将图结构信息编码到向量中，就能解决这个问题</li>
</ul>
<h1 id="faq">FAQ</h1>
<h2 id="_3">模型的主要思路是什么</h2>
<ul>
<li>跟GraphSAGE一样，其中聚合函数取的是Pooling聚合函数。</li>
<li>邻居的定义通过随机游走，到达的归一化次数最高的T个顶点</li>
<li>损失函数用的是max-margin 损失函数</li>
</ul>
<h2 id="_4">主要贡献点是什么</h2>
<ul>
<li>将GCN扩展到大规模数据集的训练和推断，可落地</li>
</ul>
<h2 id="_5">数据量有多大</h2>
<ul>
<li>节点数目 30亿</li>
<li>边数目 180亿</li>
<li>pins 有20亿</li>
<li>board 有10亿（相当于pins的收藏夹，里面是人工根据相似的pin收藏到一起的）</li>
</ul>
<h2 id="_6">图是如何构造的</h2>
<ul>
<li>是一个二部图，一个顶点集合I是pins（类似于item、poi），一个顶点集合C是boards（pins的集合，类似于session，用户（可以看做item集合））</li>
</ul>
<h2 id="_7">节点的特征是如何构造的</h2>
<ul>
<li>每一个I中的元素都有一组特征向量<ul>
<li>在Pinterest中，特征向量从文本和图片中提取</li>
<li>3类特征<ol>
<li>图像embedding特征 4096(VGG-16的第6层全连接层特征向量)</li>
<li>文本（标题和描述）embedding特征 256（利用word2vec相关方法学出来的）</li>
<li>log(node的度)</li>
</ol>
</li>
</ul>
</li>
<li>每一个C中的元素呢？？？没有特征，向量置0？</li>
</ul>
<h2 id="_8">评估方式有哪些</h2>
<ul>
<li>离线评估<ul>
<li>用一个pin作为触发，召回一批pins，评估hit-rate和mrr</li>
</ul>
</li>
<li>user study 即人工评测<ul>
<li>给一个pin的图片代表一个用户，给他用两个策略各推送一个pin，人工打分哪个更好。2/3的用户达成一致才有效。</li>
</ul>
</li>
<li>在线AB测试<ul>
<li>用repin rate来评估，10-30%的提升（相比只用文本和只用图像特征计算相似）</li>
</ul>
</li>
</ul>
<p>评估任务是：item-item推荐（即i2i推送相似的pin）；homefeed任务？</p>
<ul>
<li>给一个用户推荐步骤：找出用户最后一次pin的item，然后在embedding空间查询K个最近邻item，作为推荐的结果</li>
</ul>
<h2 id="_9">向量的应用</h2>
<ul>
<li>利用最近邻做推荐，i2i</li>
<li>作为下游推荐模型的特征</li>
</ul>
<h2 id="_10">文章做了哪些关键事情提升了扩展性</h2>
<ol>
<li>On-the-fly convolutions：去掉了全拉普拉斯矩阵运算，基于邻居采样来计算即可</li>
<li>Producer-consumer minibatch construction：producer-consumer 架构构造minibatch训练数据，保证在训练时最大限度地利用GPU</li>
<li>Efficient MapReduce inference：加速推断效率</li>
</ol>
<h2 id="_11">为什么卷积的时候要先做一层变换，而不是直接聚合</h2>
<ul>
<li>先做一层非线性变换，可以增加模型容量</li>
<li>跟正常的卷积类比，也是做一层非线性变换，最后再来一层Pooling操作</li>
</ul>
<h2 id="_12">为什么聚合之后还要再来一层变换</h2>
<ul>
<li>主要目的是为了将顶点自己的向量融合进去</li>
</ul>
<h2 id="_13">为什么不降顶点自己的向量在第一层融合的时候就融合进去</h2>
<ul>
<li>可能是为了强调自己向量，毕竟顶点自己向量比邻居向量包含的信息量更多</li>
<li>作者也有提到，用concat比avg性能提升较大，实际上说明加一层效果更好</li>
</ul>
<h2 id="concatavg">怎么理解用concat比avg性能提升较大</h2>
<ul>
<li>concat有参数，有更高的模型容量。数学上来看，前面的权重W多了一倍的参数</li>
<li>avg相当于相同的权重，学到的权重自然会比拍的权重要好一些</li>
</ul>
<h2 id="_14">为什么最后还要归一化</h2>
<ul>
<li>为了防止梯度爆炸或梯度消失？</li>
<li>作者的说法是模型训练稳定</li>
<li>在归一化的向量上做KNN更有效率（直接用余弦距离即可）</li>
</ul>
<h2 id="_15">卷积时的采样是如何进行的</h2>
<ul>
<li>不是聚合所有的邻居节点，而只根据权重采样出来的T个节点</li>
<li>好处是提高计算性能</li>
<li>不好的地方时，实现起来比较麻烦 TODO，看一下如何实现？</li>
</ul>
<h2 id="node">每个node的采样权重是如何构造</h2>
<ul>
<li>根据对该node的影响程度来加权，具体做法如下：</li>
<li>从该node出发，random walk 多次，按照经过的次数</li>
<li>当仿真无限次的时候，就相当于 Personal PageRank 算法的结果（从固定的顶点出发）</li>
<li>这样做的好处是：<ol>
<li>固定邻居数目，节省内存</li>
<li>将各顶点对该node的权重也考虑进来了</li>
</ol>
</li>
<li>TODO：试验中，random walk仿真了多少次？</li>
</ul>
<h2 id="pooling">Pooling的重要性加权是如何做的</h2>
<ul>
<li>由上述仿真出来的归一化节点权重来加权求和</li>
</ul>
<h2 id="_16">卷积的参数有哪些</h2>
<ul>
<li>两层非线性变换的权重，在node间共享，但是不同层是独立的（跟卷积类似）</li>
</ul>
<h2 id="_17">训练的监督信号？</h2>
<ul>
<li>来自有标注的item对(q, i)，即只有正样本，负样本通过负采样得到</li>
<li>通过max-margin 的rank-loss</li>
</ul>
<p>$$<br />
J(z_q, z_i) = E_{n_k \sim P_n(q)} \max{ 0, z_q\cdot z_{n_k} - z_q\cdot z_i + \Delta }<br />
$$</p>
<ul>
<li>(q, i) 对构造方法：用户在跟q交互后，又立马跟i交互，那么就构成一个正样本；实际上是就是共现关系</li>
<li>总计12亿正样本对；每个batch 500个负样本；每个pin 6 个hard负样本</li>
<li>只在图的一个子集（只选择一部分节点构造图）上训练（极大地提升训练速度）</li>
<li>20%的board和70%的样本；10%的样本用于调参（验证集）；20%的样本用于评估</li>
</ul>
<h2 id="_18">训练过程如何</h2>
<ul>
<li>多GPU卡，通过大batch的方式，每个GPU分一部分，BP算完梯度后，来一次同步SGD</li>
<li>batch size：512-4096</li>
</ul>
<h2 id="producer-consumer-minibatch-construction">Producer-consumer minibatch construction是什么</h2>
<ul>
<li>正常情况下，在做卷积时需要查询图的邻接表获取邻居节点以及节点的特征，所以会带来GPU和CPU的通信（因为无法将所有顶点特征和邻接表都塞到GPU中）</li>
<li>解决方法是，先把这个batch用到的节点构成的子图邻接表和他们的特征抽出来，在这个batch开始的时候一起送到GPU内存，那么在卷积计算的时候就不用查询CPU了</li>
<li>CPU计算使用OpenMP，CPU计算和GPU计算并行执行，避免等待</li>
</ul>
<h2 id="_19">负采样的优化</h2>
<ul>
<li>每个minibatch，事先采样500个负样本供后续采样，可以加速性能，但是效果上差异不大</li>
<li>采样的时候有限采样hard负样本（跟目标node相似的样本，实际上就是相似度加权采样，但又不能把正样本搞进去了）</li>
<li>具体做法是利用personal PageRank，得到顶点排序在2000-5000的那些item作为hard负样本</li>
</ul>
<h2 id="curriculum-training">Curriculum training 是怎么做的</h2>
<ul>
<li>第一个epoch时不加hard负样本，让模型快速找到一个较小loss的模型，从第二个epoch开始加入hard负样本</li>
</ul>
<h2 id="naivegpu">为什么naive的方法无法最大限度利用GPU</h2>
<p>正常情况下，在做卷积时需要查询图的邻接表获取邻居节点以及节点的特征，所以会带来GPU和CPU的通信（因为无法将所有顶点特征和邻接表都塞到GPU中）</p>
<h2 id="gpu">为什么文章的方法可以最大限度利用GPU</h2>
<p>先把这个batch用到的节点构成的子图邻接表和他们的特征抽出来，在这个batch开始的时候一起送到GPU内存，那么在卷积计算的时候就不用查询CPU了</p>
<h2 id="mapreduce">MapReduce推断是如何做的</h2>
<ul>
<li>简单地说，就是一层一层地算</li>
<li>每一层拆分成两步，第一步算pins向量，第二步算boards向量</li>
</ul>
<h2 id="naive">naive的方法为什么会有重复计算</h2>
<h2 id="weak-and">Weak And 是什么</h2>
<p>没搞清楚</p>
<h2 id="_20">试验的对比对象有哪些</h2>
<ol>
<li>只用视觉向量</li>
<li>只用文本向量</li>
<li>视觉+文本向量融合</li>
<li>本文的方法</li>
</ol>
<h2 id="_21">相比内容的方法，本文的方法多了什么额外的信息</h2>
<ul>
<li>本文的方法多了图结构信息</li>
<li>图结构信息来源于用户的收集行为，人工将相关的pin收集到同一个board中（本质上来说，本文方法的超额收益来源是这部分信息）</li>
</ul>
<h2 id="_22">计算资源</h2>
<ul>
<li>单机32核，16个K80 GPU，内存 500G</li>
</ul>
<h2 id="_23">离线评估指标</h2>
<ul>
<li>hit-rate：对每一对pins (q, i)，用q作为检索向量，KNN检索K=500个最近邻，如果i在这K个中，则为hit，在test集的所有样本中计算hit平均值。（就是我们之前评估召回效果用的TOP N召回率）</li>
<li>MRR：对每一对test样本pins (q, i)，用q检索得到的i的排序序号$(R_{q,i})$，那么MRR就是序号的倒数。本文做了一个简单的修改，加了个scale因子<br />
$$<br />
MRR = \frac{1}{n} \sum_{(q,i)} \frac{1}{\lceil R_{q,i}/100 \rceil}<br />
$$</li>
</ul>
<h2 id="item">查看随机两个item的余弦相似度分布有什么用</h2>
<p><img alt="余弦相似度分布" src="/wiki/static/images/pinsage-04.png" /></p>
<ul>
<li>可以查看embedding向量学到的是否有一定的区分度，避免全部item的向量距离都很近</li>
<li>最近邻检索时也能更加高效</li>
</ul>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2020-02-10 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'Graph Convolutional Neural Networks for Web-Scale Recommender Systems',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2020 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>