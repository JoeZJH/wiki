<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>Recurrent neural network based language model - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;Recurrent neural network based language model</div>
</div>
<div class="clearfix"></div>
<div id="title">Recurrent neural network based language model</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">历程</a></li>
<li><a href="#_2">模型</a></li>
</ul>
</div>
<h2 id="_1">历程</h2>
<ul>
<li>Bengio 采用神经网络做统计语言模型。前馈神经网络 + 固定窗长度<br />
Yoshua Bengio, Rejean Ducharme and Pascal Vincent. 2003. A<br />
neural probabilistic language model. Journal of Machine Learning<br />
Research, 3:1137-1155</li>
<li>Goodman 在Bengio 的基础上进行发展，发现这种简单模型比混合了其他多种方法的模型都要好。<br />
Goodman Joshua T. (2001). A bit of progress in language modeling,<br />
extended version. Technical report MSR-TR-2001-72.</li>
<li>Schwenk 发现基于神经网络的模型，能够显著提升语音识别任务，在几个任务中比最好的系统都要好。<br />
Holger Schwenk and Jean-Luc Gauvain. Training Neural Network<br />
Language Models On Very Large Corpora. in Proc. Joint Conference<br />
HLT/EMNLP, October 2005.</li>
</ul>
<p>这种方法唯一的缺点是，需要采用固定的窗长度，一般在5-10。<br />
递归神经网络理论上能够记忆任意长的信息，解决了这个问题。</p>
<p>另外一种能够实现长期依赖的方法：随机梯度下降？<br />
Yoshua Bengio and Patrice Simard and Paolo Frasconi. Learning<br />
Long-Term Dependencies with Gradient Descent is Difficult.<br />
IEEE Transactions on Neural Networks, 5, 157-166.</p>
<h2 id="_2">模型</h2>
<p>首先采用一个简单的递归神经网络，也叫Elman网络：<br />
Jeffrey L. Elman. Finding Structure in Time. Cognitive Science,<br />
14, 179-211</p>
<p>输入$(x(t))$为当前词向量$(w(t))$和上一时刻隐层状态$(s(t-1))连接成的新向量，这里用<code>+</code>表示链接，不是求和：<br />
用隐层的状态来代表上下文信息。</p>
<p>$$<br />
x(t) = w(t) + s(t-1)  \\<br />
s_j(t) = sigmoid(\sum_i x_i(t) u_{ji})  \\<br />
y_k(t) = softmax(\sum_j s_j(t) v_{kj})<br />
$$</p>
<p>模型训练：标准的 BP + SGD，一开始学习率$(\alpha=0.1)$，每一个epoch之后，在验证集上检验，如果验证集的对数似然比增加了，<br />
就继续训练，如果没有明显的改善，就将学习率减半$(\alpha_{new} = \alpha / 2 )$。如果之后仍然没有明显的改善，就停止训练。<br />
一般在10-20个epoch就能收敛。</p>
<p>作者的模型没有明显的过拟合，即使在使用正则项的情况下，也没有明显的收益。</p>
<p>误差是基于交叉熵计算的，即交叉熵的导数：</p>
<p>$$<br />
err(t) = desired(t) - y(t)<br />
$$</p>
</div>
<div>
    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<div id="content-footer">created in <span class="create-date date"> 2016-07-31 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'Recurrent neural network based language model',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/tracholar/wiki" target="_blank"> github </a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>