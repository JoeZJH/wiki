<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>【2018-Airbnb】Applying Deep Learning To Airbnb Search - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;【2018-Airbnb】Applying Deep Learning To Airbnb Search</div>
</div>
<div class="clearfix"></div>
<div id="title">【2018-Airbnb】Applying Deep Learning To Airbnb Search</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">关于</a></li>
<li><a href="#_2">摘要与导言</a></li>
<li><a href="#_3">模型演化</a><ul>
<li><a href="#simplenn">SimpleNN</a></li>
<li><a href="#lambdarank-nn">Lambdarank NN</a></li>
<li><a href="#decision-treefactorization-machine-nn">Decision Tree/Factorization Machine NN</a></li>
<li><a href="#deep-nn">Deep NN</a></li>
</ul>
</li>
<li><a href="#failed-models">FAILED MODELS</a><ul>
<li><a href="#listing-id">Listing ID</a></li>
<li><a href="#multi-task-learning">Multi-task learning</a></li>
</ul>
</li>
<li><a href="#_4">特征工程</a></li>
<li><a href="#_5">参考</a></li>
</ul>
</div>
<h2 id="_1">关于</h2>
<ul>
<li>论文: Applying Deep Learning To Airbnb Search</li>
</ul>
<h2 id="_2">摘要与导言</h2>
<ul>
<li>排序候选集只有几千个</li>
<li>算法迭代:<ol>
<li>手工打分函数</li>
<li>GBDT(很大提升,然后饱和)</li>
<li>NN</li>
</ol>
</li>
<li>模型预测目标<ol>
<li>房主接受顾客预订的概率</li>
<li>顾客给这段经历打5分的概率</li>
<li>也是目前重要考虑的点: 顾客会订购的概率</li>
</ol>
</li>
<li>搜索的特点<ul>
<li>用户会搜索多次</li>
<li>点击一些listing去查看详情</li>
<li>最终订购</li>
</ul>
</li>
<li>新模型通过老的模型部署后产生的线上数据进行训练, 得到一个打分函数</li>
<li>特征工程, 系统工程, 超参数搜索</li>
</ul>
<h2 id="_3">模型演化</h2>
<p><img src="/wiki/static/images/airbnb-model-evalution.png" style="width:400px; float: left;"/></p>
<ul>
<li>评估指标 NDCG</li>
<li>订购的相关性为1, 其他都是0</li>
<li>左图显示了不同模型的离线NDCG上的收益, SimpleNN没有GBDT好, DeepNN最好</li>
</ul>
<h3 id="simplenn">SimpleNN</h3>
<ul>
<li>单隐层, 32个隐层节点, ReLU激活函数, 击败了GBDT, 相同的特征, 最小化 L2 回归损失函数, 1订购, 0未订购 ???</li>
<li>作用: 用于验证pipeline和线上系统正确性</li>
</ul>
<h3 id="lambdarank-nn">Lambdarank NN</h3>
<ul>
<li>将 Lambdarank 的思想应用到NN上,直接上代码了(<strong>后面根据这个复现一下</strong>)</li>
</ul>
<div style="clear:both"></div>

<div class="hlcode"><pre><span></span><span class="k">def</span> <span class="nf">apply_discount</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Apply positional discount curve&#39;&#39;&#39;</span> 
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_weights</span><span class="p">(</span><span class="n">logit_op</span><span class="p">,</span> <span class="n">session</span><span class="p">):</span> 
    <span class="sd">&#39;&#39;&#39;Compute loss weights based on delta ndcg.</span>
<span class="sd">    logit_op is a [BATCH_SIZE, NUM_SAMPLES] shaped tensor corresponding to the output layer of the network.</span>
<span class="sd">    Each row corresponds to a search and each</span>
<span class="sd">    column a listing in the search result. Column 0 is the booked listing, while columns 1 through</span>
<span class="sd">    NUM_SAMPLES - 1 the not-booked listings. &#39;&#39;&#39;</span>
    <span class="n">logit_vals</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logit_op</span><span class="p">)</span> 
    <span class="n">ranks</span> <span class="o">=</span> <span class="n">NUM_SAMPLES</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span>
    <span class="n">logit_vals</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">discounted_non_booking</span> <span class="o">=</span> <span class="n">apply_discount</span><span class="p">(</span><span class="n">ranks</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span> <span class="n">discounted_booking</span> <span class="o">=</span>
    <span class="n">apply_discount</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">ranks</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> 
    <span class="n">discounted_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">discounted_booking</span> <span class="o">-</span> <span class="n">discounted_non_booking</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">discounted_weight</span>

<span class="c1"># Compute the pairwise loss</span>
<span class="n">pairwise_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span> 
    <span class="n">targets</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logit_op</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> 
    <span class="n">logits</span><span class="o">=</span><span class="n">logit_op</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">logit_op</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:]</span> <span class="p">)</span>
<span class="c1"># Compute the lambdarank weights based on delta ndcg</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">compute_weights</span><span class="p">(</span><span class="n">logit_op</span><span class="p">,</span> <span class="n">session</span><span class="p">)</span>
<span class="c1"># Multiply pairwise loss by lambdarank weights</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">pairwise_loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>
</pre></div>


<h3 id="decision-treefactorization-machine-nn">Decision Tree/Factorization Machine NN</h3>
<p><img src="/wiki/static/images/nn-gbdt-fm.png" style="width:400px; float:left" /></p>
<ul>
<li>在这个阶段主要线上模型是NN,</li>
<li>同时:<ol>
<li>用GBDT模型构造训练集 Iterations on the GBDT model with alternative ways to sample searches for constructing the training data.</li>
<li>用FM学习query和listing的相关性, 用32维向量</li>
</ol>
</li>
<li>将GDBT输出的叶子节点作为类别特征, embedding输入到NN, FM输出的相关性得分直接输入NN</li>
</ul>
<h3 id="deep-nn">Deep NN</h3>
<ul>
<li>数据集扩大10倍, 17亿对样本对, NN的隐层数目增加到2层</li>
<li>特征:<ul>
<li>价格, 环境(amenities), 历史订购次数, etc</li>
<li>智能定价价格</li>
<li>listing和该用户历史看过的listing的相似度 (就是KDD2018 best paper那篇文章)</li>
</ul>
</li>
</ul>
<h2 id="failed-models">FAILED MODELS</h2>
<ul>
<li>两个流行的方法,但是实际没有效果</li>
</ul>
<h3 id="listing-id">Listing ID</h3>
<ul>
<li>将 listing id作为特征, 然后 embedding, 输入到NN</li>
<li>试了很多版本, 加入 listing id 很容易过拟合</li>
<li>原因是listing订购数据太稀疏了,即使一年也只有365次,更不用说那些不热门的listing了</li>
</ul>
<h3 id="multi-task-learning">Multi-task learning</h3>
<ul>
<li>用长时间浏览作为辅助任务,做MTL。</li>
<li>log(view duration)作为权重?</li>
<li>试验结果发现对长时间浏览任务有较大帮助,但是对订购没有帮助</li>
</ul>
<p>Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. Beyond Clicks: Dwell Time for Personalization. In Proceedings of the 8th ACM Conference on Recommender Systems (RecSys ’14). ACM, New York, NY, USA,</p>
<h2 id="_4">特征工程</h2>
<ul>
<li>对于NN, 是为了让特征具有某些特殊的性质, 让NN能够学到复杂的计算逻辑</li>
<li>特征归一化, 均值方差归一化;  对于幂率分布, 用$(log(\frac{1 + v}{1 + median}))$归一化。为什么不用cdf?</li>
</ul>
<p><img alt="幂率分布归一化" src="/wiki/static/images/power_law_transformer.svg" /></p>
<ul>
<li>数据不是平滑的分布<ol>
<li><strong>Spotting bugs</strong> 大规模的数据中难免有少数bug数据,简单的范围限制的方法,只能找到一部分,还有一部分可以通过平滑分布找到。例如,对于某地区的价格,log之后的分布图中哪些尖锐的值很有可能就是bug数据</li>
<li><strong>Facilitating generalization</strong> DNN每一层的输出的分布越来越平滑,(下图, log(1 + relu_output))。作者认为,底层的输出分布越平滑,上层神经元越能泛化到未知数据中。作者通过抖动测试印证了这一点, 通过将测试集中的所有样本的某个特征放到2倍,3倍,观察NDCG的变化,发现观察到前所未有的稳定性。因此,作者认为要尽可能保证输入的特征分布的平滑。绝大多数特征都可以通过修复bug+合适的变换得到平滑的分布,还有一部分是需要特殊的特征工程的,listing用经纬度表示的地理位置。经纬度的原始值是不平滑的分布(图11a 和 图11b),作者使用了经纬度的相对偏移,将经纬度的原点放在用户看到的地图中心,用相对经纬度代替经纬度,分布就平滑很多(图11c 和 图11 e),作者还对相对经纬度取log得到新的一组平滑分布特征。</li>
<li><strong>Checking feature completeness</strong> 用listing的未来可订购天数作为特征, 但是原始的入住天数分布不平滑(图12 a)。通过调研,作者发现另外一个影响因素: listing有最小停留时间要求,有一些要求至少一个月!因此,他们有不同的入住率,但是我们又不能将这个作为特征放进去,因为它跟日期有关而且也太复杂了。作者添加了平均入住时长作为特征,一旦入住天数用平均入住时长归一化后,它们的比值竟然具有平滑的分布了(图12 b)!!</li>
</ol>
</li>
</ul>
<p><img alt="DNN输出分布" src="/wiki/static/images/distribute_nn_out.png" /><br />
<img alt="经纬度的变换" src="/wiki/static/images/lat_lng_transform.png" /><br />
<img alt="入住率" src="/wiki/static/images/occupancy-distribution.png" /></p>
<ul>
<li>高维类别特征</li>
</ul>
<h2 id="_5">参考</h2>
<ol>
<li><a href="https://developers.google.com/machine-learning/guides/rules-of-ml/">https://developers.google.com/machine-learning/guides/rules-of-ml/</a></li>
<li>Daria Sorokina and Erick Cantu-Paz. 2016. Amazon Search: The Joy of Rank- ing Products. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’16). 459–460.</li>
<li>Peng Ye, Julian Qian, Jieying Chen, Chen-Hung Wu, Yitong Zhou, Spencer De Mars, Frank Yang, and Li Zhang. 2018. <span style="color:red">Customized Regression Model for Airbnb Dynamic Pricing</span>. In Proceedings of the 24th ACM SIGKDD Conference on Knowl- edge Discovery and Data Mining.</li>
<li>Sebastian Ruder. 2017. An Overview of Multi-Task Learning in Deep Neural Networks. CoRR abs/1706.05098 (2017). arXiv:1706.05098 <a href="http://arxiv.org/abs/1706.05098">http://arxiv.org/abs/1706.05098</a></li>
<li>Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. Beyond Clicks: Dwell Time for Personalization. In Proceedings of the 8th ACM Conference on Recommender Systems (RecSys ’14). ACM, New York, NY, USA,</li>
<li>Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2017.Understandingdeeplearningrequiresrethinkinggeneralization. https: //arxiv.org/abs/1611.03530</li>
</ol>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-12-23 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '【2018-Airbnb】Applying Deep Learning To Airbnb Search',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2019 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>