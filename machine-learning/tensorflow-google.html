<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>tensorflow google 开源机器学习库 - tracholar's personal knowledge wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;tensorflow google 开源机器学习库</div>
</div>
<div class="clearfix"></div>
<div id="title">tensorflow google 开源机器学习库</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#tensorflow">TensorFlow 白皮书</a><ul>
<li><a href="#_1">基本概念</a></li>
<li><a href="#_2">优化</a></li>
<li><a href="#_3">工具</a></li>
</ul>
</li>
<li><a href="#_4">核心图数据结构</a></li>
<li><a href="#_5">基本数据类型</a></li>
<li><a href="#_6">优化</a></li>
<li><a href="#tfdistriblearn">tf.distrib.learn 框架</a></li>
<li><a href="#cpu-vs-gpu">CPU vs GPU</a></li>
<li><a href="#tips">TIPS</a></li>
</ul>
</div>
<h2 id="tensorflow">TensorFlow 白皮书</h2>
<p>第一代分布式机器学习框架： DistBelief。
第二代：TensorFlow，通用的计算框架！</p>
<h3 id="_1">基本概念</h3>
<ul>
<li>TensorFlow 的计算被表达为一个有向图(graph)——计算图，它由很多节点(Node)构成</li>
<li>每一个节点有0个或者多个输入，0个或者多个输出，表达了一个计算操作实例</li>
<li>正常边上流动的值被称作张量(tensor)</li>
<li>特殊边：control dependencies：没有数据流过这些边，用来控制依赖关系的</li>
<li>操作（Operation）：对计算的抽象，例如矩阵乘法，加法等。操作可以有属性，所有的属性必须被指定，或者在图构建的时候能够推断出来</li>
<li>内核（Kernel）：操作的一种特殊实现，能够在特定的设备（如CPU，GPU）上运行</li>
<li>会话（Session）：client程序与 TensorFlow 系统交互的方式， 一般创建一次，然后调用 <code>run</code> 方法执行计算图的计算操作</li>
<li>变量（Variable）：大多数 tensor 在一次计算后就不存在了，变量在整个计算图计算过程中，可以一直保持在内存。Variable 操作返回一个句柄，指向该类型的可变张量。对这些数据的操作可以通过返回的句柄进行，例如 assign, assignadd操作。一般用来保存模型参数！</li>
<li>实现：单机，分布式。client 通过 session 提交计算任务，master通过 worker 执行计算操作</li>
</ul>
<p><img src="/wiki/static/images/tf.png" style="float:left;" width="500" /></p>
<ul>
<li>
<p>设备：device，如CPU或者GPU；每一个 worker 关联一个或多个设备。每个设备都一个一个类型，和一个名字，如 <code>/job:localhost/device:cpu:0</code>
或者 <code>/job:worker/task:17/device:gpu:3</code>。其他设备类型可以通过注册的机制加入！</p>
</li>
<li>
<p>单机执行</p>
</li>
<li>多机执行：多机通信方式：TCP or RDMA</li>
<li>容错：一旦检测到错误，就重新开始；变量（Variable）会定期的保存 chekpoint。</li>
<li>梯度计算：会创建一个子图，计算梯度</li>
<li>控制流：支持 条件跳转，switch，以及循环</li>
<li>输入节点：client通过feed灌入数据，或者直接定义输入节点直接访问文件（效率更好）</li>
<li>队列：让子图异步执行的特性！FIFO队列，shuffle 队列</li>
<li>容器（container）：用于存长期可变状态，例如变量</li>
</ul>
<h3 id="_2">优化</h3>
<ul>
<li>Common Subexpression Elimination，公共子表达式消除</li>
<li>通过控制流，延迟recevier节点的通信，减少不必要的通信资源消耗</li>
<li>异步 kernel</li>
<li>采用深度优化的库：BLAS，cuBLAS，convolutional，Eigen（已扩展到支持任意维度的张量）</li>
<li>有损压缩，通信的时候采用有损压缩传递数据</li>
<li>数据并行，模型并行！</li>
</ul>
<h3 id="_3">工具</h3>
<ul>
<li>TensorBoard：训练过程可视化，计算图结构的可视化</li>
</ul>
<h2 id="_4">核心图数据结构</h2>
<p>class tf.Graph</p>
<h2 id="_5">基本数据类型</h2>
<ul>
<li>constant</li>
</ul>
<div class="hlcode"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">6.0</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="k">print</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">c</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>      <span class="c"># just syntactic sugar for sess.run(c) in the currently active session!</span>
</pre></div>


<ul>
<li>Session<ul>
<li><code>tf.InteractiveSession()</code></li>
<li>default session</li>
</ul>
</li>
<li>Variables，用来表示模型参数。<blockquote>
<p>“When you train a model you use variables to hold and
update parameters. Variables are in-memory buffers
containing tensors” - TensorFlow Docs.</p>
</blockquote>
</li>
</ul>
<div class="hlcode"><pre><span class="n">W1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s">&quot;weights&quot;</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s">&quot;random_weights&quot;</span><span class="p">)</span>
</pre></div>


<p>使用函数<code>tf.initialize_all_variables()</code>参数初始化，初始值在定义的时候给出。
如果要对变量作用域里面的所有变量用同一个初始化方法，可以在定义作用域的时候指定。
参考<a href="https://www.tensorflow.org/versions/r0.7/how_tos/variable_scope/index.html#initializers-in-variable-scope">https://www.tensorflow.org/versions/r0.7/how_tos/variable_scope/index.html#initializers-in-variable-scope</a></p>
<div class="hlcode"><pre><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;foo&quot;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">&quot;v&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">v</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="o">==</span> <span class="mf">0.4</span>  <span class="c"># Default initializer as set above.</span>
</pre></div>


<p>变量的更新，使用方法<code>tf.add</code>, <code>tf.assign</code>等方法</p>
<div class="hlcode"><pre><span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">&quot;counter&quot;</span><span class="p">)</span>
<span class="n">new_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">new_value</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>
    <span class="k">print</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>
        <span class="k">print</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

<span class="mi">0</span>
<span class="mi">1</span>
<span class="mi">2</span>
<span class="mi">3</span>
</pre></div>


<p>利用<code>tf.convert_to_tensor</code>方法可以将数值变量转换为张量。</p>
<ul>
<li>placeholder用来输入数据，通过<code>feed_dict</code>字典将输入数据映射到placeholder.</li>
</ul>
<div class="hlcode"><pre><span class="n">input1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="k">print</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">input1</span><span class="p">:[</span><span class="mf">7.</span><span class="p">],</span> <span class="n">input2</span><span class="p">:[</span><span class="mf">2.</span><span class="p">]})</span>

<span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>


<p>注意，这里有个大坑，这个字典的键是一个<code>op</code>，而不是一个字符串！！</p>
<ul>
<li>
<p>变量作用域，<code>variable_scope</code>, <code>get_variable_scope</code>, <code>get_variable</code>.
  <code>scope.reuse_variables()</code> 可以使得该作用域的变量重复使用，在RNN实现中很有用。
  声明重复利用的时候，<code>get_variable</code>的时候不是创建一个变量，而是查询保存的那个变量。</p>
</li>
<li>
<p>word embedding</p>
</li>
</ul>
<h2 id="_6">优化</h2>
<p>当得到损失函数之后，可以通过<code>tf.train.Optimizer</code>优化工具来进行优化，实际优化的时候使用的是他的子类，
如<code>GradientDescentOptimizer</code>, <code>AdagradOptimizer</code>, or <code>MomentumOptimizer</code>。
优化obj通常有以下几个重要方法可以使用。</p>
<ul>
<li><code>train_op = minimize(loss)</code>，直接最小化损失函数</li>
<li><code>compute_gradients(loss)</code>，计算梯度</li>
<li><code>train_op = apply_gradients(grad)</code>，应用梯度更新权值</li>
</ul>
<h2 id="tfdistriblearn"><code>tf.distrib.learn</code> 框架</h2>
<p>一个高级机器学习框架</p>
<ul>
<li>模型基本接口，与sklearn很像<ul>
<li><strong>init</strong>() 初始化</li>
<li><code>fit</code> 拟合</li>
<li><code>evaluate</code> 评估</li>
<li><code>predict</code> 预测</li>
</ul>
</li>
</ul>
<h2 id="cpu-vs-gpu">CPU vs GPU</h2>
<ul>
<li>Q: 自己代码在实现上有什么区别呢？</li>
</ul>
<h2 id="tips">TIPS</h2>
<ul>
<li><code>tf.reshape(some_tensor, (-1, 10))</code>将数据重新划分为10列的元素，第一维自适应</li>
<li><code>tf.device</code> 指定CPU或者GPU</li>
<li><code>tf.add_to_collection(name, value)</code>将value保存为名字为name的共享集合中，供后面使用.
  <code>tf.get_collection(name)</code>，获取存储的值</li>
<li>tensorflow里面的标量和<code>shape=[1]</code>是不同的，请注意。</li>
</ul>
<p>[1] <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>
[2] <a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf">http://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf</a></p>
</div>
<div id="content-footer">created in <span class="create-date date"> 2016-07-01 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: 'tensorflow google 开源机器学习库',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2017 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/tracholar/wiki" target="_blank"> github </a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>

    </body>
</html>