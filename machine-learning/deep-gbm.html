<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks</div>
</div>
<div class="clearfix"></div>
<div id="title">DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">摘要</a></li>
<li><a href="#_2">相关工作</a></li>
<li><a href="#deepgbm">DeepGBM</a></li>
<li><a href="#_3">试验结论</a></li>
<li><a href="#_4">疑问</a></li>
</ul>
</div>
<h2 id="_1">摘要</h2>
<ul>
<li>在线预估的两个重要的任务<ol>
<li>tabular input space</li>
<li>online data generation</li>
</ol>
</li>
<li>GBDT和NN都有自己的弱点<ul>
<li>GBDT弱点在于sparse特征</li>
<li>NN弱点在于dense特征</li>
</ul>
</li>
<li>DeepGBM两个模块<ul>
<li>CatNN 处理sparse特征的NN</li>
<li>GBDT2NN 处理dense特征, 将GBDT中学到的知识、特征重要性、特征分割点等知识蒸馏到NN中</li>
</ul>
</li>
<li>GBDT的两个问题<ul>
<li>不能做online learning, 也意味着难以处理极大规模的训练数据</li>
<li>对(高度)稀疏特征难以拟合得很好。因为分裂是根据特征的统计信息,而稀疏特征onehot之后,分裂对单个特征的统计信息的变化很小,所以难以拟合的很好。一些解决的方法,将sparse特征通过一些编码方法变成连续特征。但每一种编码方法都有其局限性,无法充分表示原有特征中的信息量。<ul>
<li>sklearn的一个编码库 <a href="https://github.com/scikit-learn-contrib/categorical-encoding">https://github.com/scikit-learn-contrib/categorical-encoding</a></li>
<li>onehot之后的统计信息还有偏? LightGBM</li>
</ul>
</li>
</ul>
</li>
<li>NN的问题<ul>
<li>dense特征拟合效果通常不如GBDT,原因是局部最优。我认为还有模型结构的限制也是一个原因,因为dense特征要拟合好需要高度非线性,那么需要很深的NN,而这导致优化更加困难</li>
</ul>
</li>
</ul>
<h2 id="_2">相关工作</h2>
<ul>
<li>GBDT在线学习方法<ul>
<li>XGBoost、LightGBM 固定树结构,改变叶子节点的权重</li>
</ul>
</li>
<li>GBDT处理sparse特征<ul>
<li>CatBoost, 通过target statistic信息将sparse特征编码成连续值特征</li>
</ul>
</li>
<li>深度GBDT<ul>
<li>周志华的两篇文章,DeepForest和mGBDT,将树模型多层堆叠起来</li>
</ul>
</li>
<li>DNN处理连续特征<ul>
<li>归一化、正则</li>
<li>离散化:  Supervised and unsupervised discretization of continuous features</li>
</ul>
</li>
<li>DNN与GBDT结合的工作<ul>
<li>Facebook将GBDT的叶子节点作为sparse特征</li>
<li>Microsoft用GBDT学习NN的残差</li>
</ul>
</li>
</ul>
<h2 id="deepgbm">DeepGBM</h2>
<ul>
<li>CatNN sparse特征, 目前主流的DNN都可以使用,没有限制</li>
<li>GDBT2NN dense 特征<ul>
<li>树的特征选择信息。用$(I^t)$表示第t棵树的特征选择向量,即第k个元素为1表示第k个特征被第t棵树选择用于构建决策树。然后只是用这些选出来的特征$(x(I^t))$来构建NN</li>
<li>树结构蒸馏。训练一个神经网络,用$(x(I^t))$作为输入特征,用决策树的输出叶子节点ID作为target。$(\theta)$是NN的参数,$(L^{t,i})$表示原始训练数据中第i个样本被第t棵树分到的叶子节点ID的onehot编码, L是交叉熵损失函数<br />
$$<br />
\min_{\theta} \frac{1}{n}\sum_{i=1}^n L(NN(x^i[I^t]; \theta), L^{t,i}) <br />
$$</li>
<li>叶子节点输出。<strong>叶子节点输出向量$(q^t)$不用学习,直接映射即可</strong>。最终决策树输出为<br />
$$<br />
y^t(x) = NN(x[I^t]; \theta) \times q^t<br />
$$</li>
<li>多棵树的蒸馏, 直接用多个NN来拟合多个树太低效了<ul>
<li>leaf embedding 蒸馏, $(p^{t,i})$ 是预测值,直接用一个NN将leaf id映射到预测值,从而得到leaf embedding向量$(H^{t,i}=H(L^{t,i}; w^t))$。这样一来也可以将树结构蒸馏的target改为$(H^{t,i})$<br />
$$<br />
\min_{w,w_0,w^t} \frac{1}{n}\sum_{i=1}^n L(w^TH(L^{t,i}; w^t) + w_0, p^{t,i}) \\<br />
\min_{\theta} \frac{1}{n}\sum_{i=1}^n L(NN(x^i[I^t]; \theta), H^{t,i})<br />
$$</li>
<li>tree grouping: 从一组tree中做蒸馏<ul>
<li>如何分组: 随机均匀分组、根据重要性均匀分组etc,文中使用随机,目测差异不会很大</li>
<li>如何蒸馏: 输入由单棵树的叶子id onehot值$(L^{t})$变成多个树的concat, target变成多个叶子节点的和! concat之后embedding向量(相当于多个embedding向量之和)作为NN蒸馏学习的target。NN蒸馏的输入则是该组决策树用到的特征,也可以根据特征重要性取TOP。<br />
$$<br />
\min_{w,w_0,w^t} \frac{1}{n} \sum_{i=1}^n L(w^TH(concat_{t\in T}L^{t,i}; w^t) + w_0, \sum_{t\in T} p^{t,i}) \\<br />
G^i = H(concat_{t\in T}L^{t,i}; w^t)<br />
$$</li>
</ul>
</li>
<li>最终GBDT2NN的输出是多个模型最终输出之和。</li>
</ul>
</li>
</ul>
</li>
<li>DeepGBM训练:<ul>
<li>端到端离线训练,批量更新。首先训练一个GBDT,然后利用叶子节点id和权重训练出leaf embedding; 然后端到端训练,一方面利用leaf embedding训练一个新的NN对模型结构做蒸馏构,造出对GBDT结构蒸馏损失,另一方面利用GBDT2NN的输出与CatNN的输出加权和拟合的误差损失。相当于蒸馏结构损失作为一个辅助任务或正则项。k是决策树分组数, $(L^{T_j})$代表该分组的对leaf embedding的拟合损失。<br />
$$<br />
\hat{y}(x) = \sigma(w_1\times y_{GBDT2NN}(x) + w_2\times y_{cat}(x)) \\<br />
L_{offline} = \alpha L(\hat{y}(x), y) + \beta\sum_{j=1}^{k} L^{T_j}<br />
$$</li>
<li>在线学习: 只更新拟合误差损失部分(及上式的第一部分作为在线更新损失)。问题: 那么这种方法跟直接用GBDT叶子id作为额外的NN sparse特征的方法有什么优势?因为二者都没有更新GBDT模型</li>
</ul>
</li>
</ul>
<h2 id="_3">试验结论</h2>
<ul>
<li>将GBDT蒸馏为NN这一步离线性能上有轻微的额外收益</li>
<li>将GBDT和NN联合训练比单独的GBDT和单独的NN有额外收益</li>
<li>将GBDT蒸馏为NN这一步对在线更新上有显著收益</li>
<li>开源代码 <a href="https://github.com/motefly/DeepGBM">https://github.com/motefly/DeepGBM</a></li>
</ul>
<h2 id="_4">疑问</h2>
<ul>
<li>为啥FM和wide &amp; deep在这种CTR预估数据集上的性能被采用了label encoded处理过sparse特征后的LightGBM完虐? 似乎不太符合常理?</li>
</ul>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2019-08-09 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2019 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>