<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>Pattern Recognition and Machine Learning - Bishop - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;Pattern Recognition and Machine Learning - Bishop</div>
</div>
<div class="clearfix"></div>
<div id="title">Pattern Recognition and Machine Learning - Bishop</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">关于</a></li>
<li><a href="#_2">引言</a><ul>
<li><a href="#_3">曲线拟合</a></li>
<li><a href="#11">第11章 采样方法</a><ul>
<li><a href="#_4">基本采样方法</a></li>
<li><a href="#_5">拒绝采样</a></li>
<li><a href="#_6">重要性采样</a></li>
<li><a href="#em">采样与EM算法</a></li>
<li><a href="#mcmc">马尔科夫链蒙特卡洛MCMC</a></li>
<li><a href="#_7">吉布斯采样</a></li>
<li><a href="#slice">slice采样</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<h1 id="_1">关于</h1>
<p>Bishop写得PRML无疑是机器学习领域的权威著作，是加强机器学习理论知识必看的书籍之一。<br />
这里是我在阅读这本书时记录的笔记和自己的一些初步思考。</p>
<h1 id="_2">引言</h1>
<h2 id="_3">曲线拟合</h2>
<p>设曲线拟合的目标变量为$(t)$，$(N)$个训练集为<br />
$( \mathbf{x} = (x_1, ..., x_N)^T )$，对应的目标值为<br />
$( \mathbf{t} = (t_1, ..., t_N)^T )$。假设估计误差服从<br />
高斯分布<br />
$$<br />
p(t|x, \mathbf{w}, \beta) = \mathcal{N} (t| y(x, \mathbf{w}), \beta^{-1}) <br />
$$<br />
这里的$(\mathbf{w})$是待估计的参数，$(\beta^{-1})$对应于<br />
估计误差的方差。此时，按照最大似然准则估计的参数就是最小二乘<br />
法的结果，也就是最小化均方误差。而$(\beta^{-1})$的最大似然估计为<br />
模型预测值与实际值的均方差。<br />
$$<br />
\frac{1}{\beta} = \frac{1}{N} \sum_{n=1}^N [y(x_n,\mathbf{w}_{ML}) - t_n]^2.<br />
$$</p>
<p>如果我们对参数的具有一定先验知识，可以进一步采用最大后验概率估计，<br />
得到更好的结果。作为一个特例，如果认为<br />
$$<br />
p(\mathbf{w}|\alpha) = \mathcal{N}(\mathbf{w} | 0, \alpha^{-1} \mathbf{I})   \\<br />
                    = (\frac{\alpha}{2\pi})^{(M+1)/2} \exp(-\frac{\alpha}{2} \mathbf{w}^T \mathbf{w}).<br />
$$<br />
那么此时的最大后验概率估计为带$(L_2)$正则项的估计，<br />
它最小化<br />
$$<br />
\frac{\beta}{2} \sum_{n=1}^N [y(x_n, \mathbf{w}) -t_n]^2 + \frac{\alpha}{2} \mathbf{w}^T \mathbf{w}<br />
$$<br />
也就是说正则项是对模型参数的一种先验知识，$(L_2)$正则项代表高斯先验。<br />
那$(L_1)$代表laplace先验(待求证)？</p>
<h2 id="11">第11章 采样方法</h2>
<ul>
<li>计算期望 $(E[f] = \int f(z)p(z) dz)$</li>
<li>通过采样一系列$(z_i ~ p(z))$ ,从而近似地用有限和来近似上述期望$(\hat{f} = \frac{1}{L}\sum_{l=1}^Lf(z_l))$</li>
<li>估计误差可以用上述统计量的方差来刻画</li>
</ul>
<h3 id="_4">基本采样方法</h3>
<ul>
<li>一维分布变换关系 $(p(y) = p(z) \frac{dz}{dy})$</li>
<li>分布f(y)可以通过从[0,1]间均匀随机变量z,通过变换$(F^{-1}(z))$得到, F是y的累积分布函数</li>
<li>指数分布$(y = F^{-1}(z) = -\frac{1}{\lambda} ln(1-z))$</li>
<li>对于多维分布,通过雅克比矩阵 $(p(y_1, ..., y_M) = p(z_1, ..., z_M)|\frac{\partial(z_1,...,z_M)}{\partial(y_1,...,y_M)}|)$</li>
<li>高斯分布生成: Box-Muller方法<ul>
<li>$(z_1,z_2)$独立采样自服从(-1,1)之间的均匀分布</li>
<li>只保留在单位圆内的点,即满足$(z_1^2 + z_2^2 \le 1)$,从而得到单位圆内的均匀分布</li>
<li>构造新的变量$(y_1 = z_1(\frac{-2 ln r}{r^2})^{1/2}, y_2 = z_2 (\frac{-2 ln r}{r^2})^{1/2})$. 其中r是半径, 那么y1和y2就是两个独立的服从标准正太分布的随机变量</li>
<li>假设两个随机变量z1,z2服从正太分布,那么对应的极坐标r和$(\theta)$对应的分布是 $(r e^{-\frac{r^2}{2}})$ 和 $(\frac{1}{2\pi})$的均匀分布。显然这两个分布可以通过均匀分布通过逆变换的方法容易得到。<br />
$$<br />
r = \sqrt{-2 ln U_1} \\<br />
\theta = 2\pi U_2<br />
$$<br />
如果是从单位圆内的变换过来,那么容易验证对应的$(\theta)$即满足第二个均匀分布,而半径s分布为$(2s)$,所以根据概率恒等关系有<br />
$$<br />
2s ds = r e^{-\frac{r^2}{2}} dr<br />
$$<br />
解这个微分方程可得 $(r = \sqrt{ln s} )$, 同时$(cos(\theta) = x/s, sin(\theta) = y/s)$,于是有 <br />
$$<br />
z_1 = r cos(\theta) = x \sqrt{ln s}/s, \\<br />
z_2 = r sin(\theta) = y \sqrt{ln s}/s<br />
$$</li>
</ul>
</li>
<li>一般的高斯分布$(\mu, \Sigma)$,将协方差矩阵分解为$(LL^T)$,那么对独立的标准正太分布向量z,做变换$(\mu + L z)$ 即可得到目标分布</li>
</ul>
<div class="hlcode"><pre><span></span><span class="k">def</span> <span class="nf">urnd</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">exp_rnd</span><span class="p">(</span><span class="n">lb</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">lb</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">urnd</span><span class="p">()</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">lb</span><span class="o">*</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gaussian_rnd</span><span class="p">():</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">urnd</span><span class="p">()))</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">urnd</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">r</span> <span class="o">*</span> <span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cauchy_rnd</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">urnd</span><span class="p">()</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">pi</span>
    <span class="k">return</span> <span class="n">tan</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cauchy_rnd2</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">gaussian_rnd</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">gaussian_rnd</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">y</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cauchy_rnd</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">/</span><span class="n">y</span>
</pre></div>


<ul>
<li>cauchy分布 $(p(x) = \frac{1}{\pi} \frac{1}{1+x^2})$<ul>
<li>通过逆变换方法, z采样自U(0,1), 逆变换为 tan((z-0.5)*pi)</li>
<li>构造两个标准正态分布X,Y,那么X/Y 则服从cauchy分布</li>
</ul>
</li>
<li>对第2点的证明, 做变量代换t=X/Y, 那么P(t_0&lt;X/Y&lt;t_0+dt)的概率微元为<br />
$$<br />
P(t_0)dt = \iint_{t_0&lt;X/Y&lt;t_0+dt} p_X(x)p_Y(y)dxdy \\<br />
= dt \int_{-\infty}^{\infty} dy |y| p_X(t_0y)p_Y(y)  \text{(积分变换)} \\<br />
= dt \int_{-\infty}^{\infty} dy \frac{1}{2\pi} |y|e^{-\frac{1}{2}(t_0^2+1) y^2} \\<br />
= \frac{1}{\pi} \frac{1}{1+t_0^2} dt<br />
$$</li>
</ul>
<h3 id="_5">拒绝采样</h3>
<ul>
<li>目标分布p(z)不简单(比如没有解析表达式,或者有但是逆变换很困难etc),但是p(z)对给定的z还是要容易算出来</li>
<li>对于已有的某种分布q(z),选取足够大的k使得$(kq(z) \le p(z))$</li>
<li>每次采样的时候,首选从q中采样一个z,然后随机一个(0, kq(z))均匀分布u,如果$(u&gt;p(z))$则拒绝该样本,否则就得到目标分布的一个采样。容易验证这样采出来的z分布为 $(q(z) \times p(z)/kq(z) = p(z))$</li>
</ul>
<p><img alt="拒绝采样" src="/wiki/static/images/prml-reject-samping.png" /></p>
<ul>
<li>kq尽可能和目标分布接近,否则采样效率很低,比如下述例子</li>
</ul>
<div class="hlcode"><pre><span></span><span class="c1">## 利用拒绝采样a&gt;1和b&gt;1的beta分布随机变量</span>
<span class="k">def</span> <span class="nf">reject_samping_beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">&gt;</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">b</span><span class="o">&gt;</span><span class="mi">1</span>
    <span class="n">reject</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">z</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">reject</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">urnd</span><span class="p">()</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">z</span><span class="o">**</span><span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">z</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">urnd</span><span class="p">()</span>
        <span class="n">reject</span> <span class="o">=</span> <span class="n">u</span> <span class="o">&gt;</span> <span class="n">p</span>
    <span class="k">return</span> <span class="n">z</span>
</pre></div>


<ul>
<li>Gamma分布的例子<br />
$$<br />
Gam(z|a,b) = \frac{b^a z^{a-1} \exp(-b z)}{\Gamma(a)}, a&gt;1<br />
$$</li>
</ul>
<p>选取$(c = a − 1, b^2 = 2a − 1)$,柯西分布 $(q(z) =\frac{k}{1 + (z − c)2/b^2})$ 选取足够小的k可以逼近gamma分布的包罗</p>
<h3 id="_6">重要性采样</h3>
<ul>
<li>不是生成目标分布的采样,而是直接近似在这个分布下的期望值。</li>
<li>p(z) 容易计算,但是不容易生成该分布的采样,比如gamma分布</li>
<li>假设容易采样分布为q(z), 那么期望<br />
$$<br />
E_p[f] = \int f(z)p(z) dz = \int \frac{p(z)}{q(z)}f(z) q(z) dz \\<br />
       = E_q[\frac{p(z)}{q(z)}f(z)]<br />
$$<br />
其中$(\frac{p(z)}{q(z)})$为重要性权重</li>
<li>优点:所有的采样样本都保留了下来</li>
<li>缺点:跟拒绝采样一样,p和q分布要尽可能差异小,否则采样效率也比较低。比如总是采样到很小概率的区域</li>
<li>sampling-importance-resampling SIR<ol>
<li>先从分布q中采样L个样本$(z_1, ..., z_L)$</li>
<li>计算重要性权重(可以不用归一化概率) $(w_1,...,w_L)$</li>
<li>从L个样本中用重要性权重加权采样L个新样本$(z_1, ..., z_L)$</li>
</ol>
</li>
<li>优点:所有样本都保留了下来, 能在一定程度上解决采样效率低的问题</li>
<li>缺点: L很小的时候存在的固有偏差较大。比如L=1的时候,会导致实际采样的分布等于q(z),只有到L趋近于无穷的时候,才没有偏差</li>
</ul>
<h3 id="em">采样与EM算法</h3>
<ul>
<li>蒙特卡洛EM算法,在求Q函数的时候,利用采样的方法来估计积分的值。</li>
<li>缺少一个例子来理解。。。。。。。。。。。</li>
<li>IP算法P537页,以后再说</li>
</ul>
<h3 id="mcmc">马尔科夫链蒙特卡洛MCMC</h3>
<ul>
<li>能够处理一大类分布的问题, 能够容易扩展到样本向量维度很高的问题</li>
<li>马尔科夫链平稳条件(充分条件) 意义是: 从z跳转到z'的联合概率,与从z'到z的联合概率相等<br />
$$<br />
p(z) T(z, z') = p(z') T(z', z)<br />
$$</li>
<li>目标:构造一个马氏链, 稳态分布是目标分布p(z),就可以采样出无穷多的样本了</li>
<li>假设目标分布是p,用户构造出来的转移概率为q(z|z^{t}),利用拒绝采样的方法来配平上述平稳条件,假设接受概率为A(z|z^{t}),那么要求<br />
$$<br />
p(z^{t})q(z|z^{t})A(z|z^{t}) = p(z)q(z^{t}|z)A(z^{t}|z)<br />
$$<br />
为了使上式平衡,可以让接受率跟转移的联合概率成反比。选取$(A(z|z^{t}) = min(1, \frac{p(z)q(z^{t}|z)}{p(z^{t})q(z|z^{t})}))$<br />
即,如果左边大于右边,那么右边以概率1接受,左边以小于1的概率接受。</li>
<li>一个变量,多个离散状态的情况模拟, 即让 i-&gt;j 的联合概率 等于 j-&gt;i 的联合概率</li>
</ul>
<div class="hlcode"><pre><span></span><span class="k">def</span> <span class="nf">rand_i</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">/</span><span class="n">w</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="k">while</span> <span class="n">s</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">:</span>
        <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">j</span>
<span class="k">def</span> <span class="nf">MetropolisHastings</span><span class="p">():</span>
    <span class="n">p_target</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.25</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">rx</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rand_i</span><span class="p">(</span><span class="n">q</span><span class="p">[</span><span class="n">x0</span><span class="p">])</span>
        <span class="n">aij</span> <span class="o">=</span> <span class="n">p_target</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">x0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">p_target</span><span class="p">[</span><span class="n">x0</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="n">x0</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span>  <span class="c1"># 接受率</span>
        <span class="n">aij</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">aij</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">urnd</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">aij</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>
            <span class="n">rx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">x</span> <span class="c1"># update</span>
    <span class="k">return</span> <span class="n">rx</span>
</pre></div>


<h3 id="_7">吉布斯采样</h3>
<ul>
<li>不用拒绝采样,直接通过巧妙地构造转移概率来实现等式配平。构造方法是:<ol>
<li>以某个次序(具体的次序不重要,随机都行)选择z的某个维度z_i。</li>
<li>计算条件概率$(p(z_i|z_{i-}))$,$(z_{i-})$表示除了zi外的其他维度变量</li>
<li>用条件概率采样的zi代替当前的zi</li>
</ol>
</li>
<li>这样一来,p(z)是联合分布的边际分布,q(z|z')是个路径相关的条件分布(参考下面说的2维的情况),所以等式左右两边都等于联合分布除以一个共同的常数,配平了!!</li>
<li>原因解释, 因为在每一步, 只变动一个维度,而且这个维度的采样概率只依赖于剩下的变量。因此容易验证<br />
$$<br />
A(z|z^{t}) = \frac{p(z)q(z^{t}|z)}{p(z^{t})q(z|z^{t})} = 1<br />
$$</li>
<li>假设一维情况下, q(z|z') = p(z),所以等式两边都是 p(z)p(z')</li>
<li>假设2维情况<ol>
<li>第一步 (x_1, y_1) -&gt; (x_1, y_2); x_1不变,等式两边都是 p(x_1,y_1)p(x_1,y_2)/p(x_1) 是关于 y_1, y_2对称的 </li>
<li>第二步 (x_1, y_2) -&gt; (x_2, y_2); y_2不变,等式两边都是 p(x_1, y_2)p(x_2, y_2)/p(y_2) 是关于 x_1,x_2对称的</li>
<li>总的结果是等式左右两边都等于 p(x_1,y_1)p(x_1,y_2)p(x_2,y_2)/p(x_1)/p(y_2) 所以马氏链配平了</li>
</ol>
</li>
</ul>
<p><img alt="吉布斯采样" src="/wiki/static/images/gibss-samping.png" /></p>
<ul>
<li>参考链接: <a href="https://www.cnblogs.com/xbinworld/p/4266146.html">https://www.cnblogs.com/xbinworld/p/4266146.html</a></li>
</ul>
<h3 id="slice">slice采样</h3>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2016-05-30 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'Pattern Recognition and Machine Learning - Bishop',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2020 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>