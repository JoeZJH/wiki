<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>Rerank机制调研 - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;<a href="/wiki/#-recommend">recommend</a>&nbsp;»&nbsp;Rerank机制调研</div>
</div>
<div class="clearfix"></div>
<div id="title">Rerank机制调研</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">问题</a></li>
<li><a href="#_2">传统方法</a></li>
<li><a href="#2009">微软2009</a></li>
<li><a href="#-icml2008">多臂老虎机-ICML2008</a><ul>
<li><a href="#-learning-diverse-rankings-with-multi-armed-bandits">- Learning diverse rankings with multi-armed bandits</a></li>
</ul>
</li>
<li><a href="#mmr">MMR</a></li>
<li><a href="#xquad">xQuAD</a></li>
<li><a href="#svmdiv">SVMDiv</a></li>
<li><a href="#_3">多样性</a></li>
<li><a href="#mdp-2017">MDP-2017</a></li>
<li><a href="#rank">优化整个页面的rank</a></li>
<li><a href="#globally-rank">阿里：Globally Rank</a></li>
<li><a href="#rerank">阿里：个性化rerank</a></li>
<li><a href="#dpp">DPP：行列式点过程</a><ul>
<li><a href="#_4">行列式点过程</a><ul>
<li><a href="#_5">例子</a></li>
<li><a href="#l-ensembles">L-ensembles</a></li>
<li><a href="#dpp_1">DPP的应用</a></li>
<li><a href="#dpp_2">DPP采样</a></li>
</ul>
</li>
<li><a href="#google-youtube">Google YouTube</a><ul>
<li><a href="#deep-gramian-kernels">Deep Gramian Kernels</a></li>
<li><a href="#efficient-ranking-algorithm-with-dpp">Efficient Ranking Algorithm with DPP</a></li>
<li><a href="#_6">实验</a></li>
<li><a href="#_7">结论和未来规划</a></li>
<li><a href="#_8">思考</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<h1 id="_1">问题</h1>
<ul>
<li>现有的推荐模型基本上都是预测一个得分f(u, i)，是一个pointwise模型。而实际上排序时，对i的打分还依赖前后的item，所以应该是listwise模型。rerank就是为了解决这个问题</li>
</ul>
<h1 id="_2">传统方法</h1>
<ul>
<li>在排序中，可以利用lambdaMart，优化list的损失函数来实现</li>
</ul>
<h1 id="2009">微软2009</h1>
<ul>
<li>Diversifying Search Results</li>
<li>基本思路是在排序得到一个文档集合之后，先初始化一个空集，然后贪心地将边际收益最大的文档加入集合中</li>
<li>边际收益的定义。假设有很多个类别，query和document都有一定概率属于某个类别。用$( V(d| q, c) )$ 表示在query为q，类别c的条件下，出文档d的价值（比如相关性）；用$( U(c | q, S) )$ 表示在集合S都不属于c类别条件下，q属于类别c的概率。那么在列表S中加入文档d带来的边际收益（额外增加的价值）可以表示为：现有的S都不是c类别但query的意图是c类别，此时文档d带来的收益为V(d|q,c)。对所有类别求期望有<br />
$$<br />
g(d|q, c,S) = \sum_{c \in C(d)} U(c|q,S) V(d|q,c)<br />
$$<br />
C(d)是文档d的所属类别集合（文档可以属于多个类别）。</li>
<li>当在集合S中增加文档d后，条件概率$(U(c | q, S \cup {d}))$的更新表达式为<br />
$$<br />
U(c|q, S \cup {d}) = (1 - V(d|q,c))U(c | q, S)<br />
$$</li>
</ul>
<h1 id="-icml2008">多臂老虎机-ICML2008</h1>
<h2 id="-learning-diverse-rankings-with-multi-armed-bandits">- Learning diverse rankings with multi-armed bandits</h2>
<h1 id="mmr">MMR</h1>
<ul>
<li>The use of mmr, diversity-based reranking for reordering documents and producing summaries</li>
<li>最大化边际相关性</li>
<li>对于给定的文档集合S，往里面加一个新的文档d的边际相关性为<br />
$$<br />
\lambda Sim_1(d, q) - (1-\lambda) \max_{d_i \in S} Sim_2(d, d_i)<br />
$$<br />
即为文档d与q的相关性减掉d与S中所有文档中最大相关性！</li>
</ul>
<h1 id="xquad">xQuAD</h1>
<ul>
<li>预定义效用函数，对相关性和多样性加权，多样性的衡量是改写的qi和现有集合S中的文档都不相关但与文档d相关的概率。<br />
$$<br />
(1-\lambda P(d|q)) + \lambda \sum_{q_i \in Q}P(q_i|q)P(d|q_i) \Pi_{d_j \in S} (1-P(d_j|q_i))<br />
$$</li>
</ul>
<h1 id="svmdiv">SVMDiv</h1>
<h1 id="_3">多样性</h1>
<ul>
<li>Learning for search result diversification</li>
</ul>
<h1 id="mdp-2017">MDP-2017</h1>
<ul>
<li>Adapting markov decision process for search result diversification</li>
</ul>
<h1 id="rank">优化整个页面的rank</h1>
<ul>
<li>Beyond ranking: Optimizing whole-page presentation</li>
</ul>
<h1 id="globally-rank">阿里：Globally Rank</h1>
<ul>
<li>Globally Optimized Mutual Influence Aware Ranking in E-Commerce Search</li>
<li>将问题建模为估计$(p(i|c(o, i)))$ c是上下文中的item，上下文是指排序展示结果中有的item</li>
<li>关键是构造global特征，global特征构造方法是算一个全局分位点值<br />
$$<br />
f' = \frac{f - f_{min}}{f_{max} - f_{min}}<br />
$$</li>
<li>最后将rerank建模成一个序列生成模型，用RNN来做decoder，用beam search来做搜索</li>
<li>lambdaMART用了listwise的损失函数，但是模型没有使用展示的list中的信息，这里的一个创新点应该是还利用到了list中的信息来做特征，建模这个得分。</li>
</ul>
<h1 id="rerank">阿里：个性化rerank</h1>
<ul>
<li>
<p>Personalized Re-ranking for Recommendation<br />
<img alt="PRM" src="/wiki/static/images/prm.png" /></p>
</li>
<li>
<p>recsys2019年，阿里发表的文章</p>
</li>
<li>将问题建模为对排序后的每一个item计算一个得分 $(P(y_i | X, PV; \theta))$，其中X是该list所有item的特征矩阵，PV是一个正常pointwise排序模型（比如W&amp;D）最后一个隐层输出向量，作为用户和这个item的个性向量</li>
<li>本质上是建模一个序列(排序后的item列表)到另一个序列(每一个item的打分序列)的问题</li>
<li>将item特征向量和pv向量拼接，在加上position Encoder向量，通过一个transformer来建模这个序列到序列的变换模型；最后一层是一个softmax，监督信号是点击之类的信号</li>
</ul>
<h1 id="dpp">DPP：行列式点过程</h1>
<ul>
<li>参考 <a href="http://people.csail.mit.edu/stefje/fall15/notes_lecture21.pdf">http://people.csail.mit.edu/stefje/fall15/notes_lecture21.pdf</a></li>
<li>Determinantal Point Processes for Machine Learning <a href="http://www.alexkulesza.com/pubs/dpps_fnt12.pdf">http://www.alexkulesza.com/pubs/dpps_fnt12.pdf</a></li>
</ul>
<h2 id="_4">行列式点过程</h2>
<ul>
<li>一个点过程P是行列式点过程是指，如果Y是一个采样自P的随机子集，那么对任意 $(S \subset Y)$，有<br />
$$<br />
P(S \subset Y) = \det(K_S)<br />
$$<br />
其中$(K)$是一个实对称半正点相似矩阵，$(K_S)$代表子集S作为下标集合表示的子矩阵。</li>
<li>由于K的任意子矩阵的行列式表示一个概率所以，K的特征值应该都在[0,1]区间，因此有$(0 \le K \le 1)$</li>
<li>$(P(e_i \in Y)= K_{ii})$</li>
<li>$(P(e_i, e_j \in Y)= K_{ii}K_{jj} - K_{ij}^2 = P(e_i \in Y) P(e_j \in Y) - K_{ij}^2)$，也就是两个元素同时出现的概率小于分别出现概率的乘积！！这表明这两个元素是互斥的！Kij越大，表示这两个元素同时出现的概率越小！</li>
<li>如果 $(K_{ij} = \sqrt{K_{ii} K_{jj}})$ 表示i和j是完全相似的，这两个item同时出现的概率接近于0！</li>
<li>当没有交叉项，也就没有斥力项，此时K是对角阵，不同元素之间互相独立！</li>
</ul>
<h3 id="_5">例子</h3>
<ul>
<li><a href="https://arxiv.org/pdf/0904.3740.pdf">https://arxiv.org/pdf/0904.3740.pdf</a></li>
<li>长度为N的序列，每个元素是从集合I中选出，从这个序列的第二个元素开始，如果当前元素小于前面一个数，那么就把这个元素的下标选出，这些下标的分布构成一个行列式点过程。</li>
</ul>
<h3 id="l-ensembles">L-ensembles</h3>
<ul>
<li>对一个实对称阵L，点过程 $(Y \subset V)$ 的未归一化概率为<br />
$$<br />
P_L(Y) \propto \det(L_Y) <br />
$$</li>
<li>如何计算归一化常数。有下列定理(⚠️)</li>
<li>对任意$(A \subset V)$<br />
$$<br />
\sum_{A \subset Y \subset V} \det(L_Y) = \det(L + I_{\bar{A}})<br />
$$<br />
其中$(I_{\bar{A}})$ 是一个对角阵，A中下标对应的对角元素是0，非A中的下标对角元为1.</li>
<li>当 $(A = \phi)$空集时，就得到L-ensembles的归一化常数为<br />
$$<br />
\sum_{S \subset V} \det(L_S) = \det(L + I_V)<br />
$$</li>
<li>用核矩阵（归一化的）K和实对称阵L定义DPP是等价的，并且这两个矩阵有关系<br />
$$<br />
K = L(L + I)^{-1} = I - (L + I)^{-1} \\<br />
L = (I - K)^{-1} - I = K (I - K)^{-1}<br />
$$</li>
<li>特征值分解，如果L的特征值分解为 $(L = \sum_k \lambda_k v_k v_k^T)$，那么$(K = \sum_k \frac{\lambda_k}{\lambda_k + 1} v_k v_k^T)$</li>
<li>几何视角：点过程$(x_1,...,x_n)$是n维空间中的点过程，那么可以构造矩阵$(L_{ij} = x_i^T x_j)$，那么 ⚠️<br />
$$<br />
P_L(S) \propto \det(L_S) = Vol^2(\{x_i\}_{i \in S}) <br />
$$<br />
如果一个集合包含的点具有更多的多样性，那么体积也就越大，所以概率也就越大。</li>
</ul>
<h3 id="dpp_1">DPP的应用</h3>
<ul>
<li>尽管DPP的可能子集数目是指数规模$(2^N)$，但是DPP的很多概率推断却可以在多项式时间复杂度完成！</li>
<li>如果$( Y \sim DPP(K) )$，那么Y的补集 $( \bar{Y} \sim DPP(I - K) )$   ⚠️<br />
$$<br />
P(A \cap Y = \phi) = \det(I - K_A)<br />
$$</li>
<li>其他略，参考原始材料吧</li>
<li>DPP众数，找到一个集合Y，最大化概率$(P_L(Y))$是一个NP-hard问题</li>
</ul>
<h3 id="dpp_2">DPP采样</h3>
<ul>
<li>问题：<ul>
<li>如何采样</li>
<li>样本中有多少个点</li>
</ul>
</li>
<li>element DPP：如果核矩阵的特征值为{0,1}。一个DPP可以看做多个基础DPP的混合！</li>
<li>定理：一个DPP，$(L = \sum_k \lambda_k v_k v_k^T)$ 可以看做多个基础的DPP的混合：$(P_L = \frac{1}{\det(L + I)} \sum_{T \subset U} \Pi_{k\in T} \lambda_k P^T)$    </li>
</ul>
<h2 id="google-youtube">Google YouTube</h2>
<ul>
<li>Practical Diversified Recommendations on YouTube with Determinantal Point Processes</li>
<li>rerank的目标，最大化总交互数目<br />
$$<br />
G' = \sum_{u \sim user} \sum_{i \sim item} y_{ui}<br />
$$</li>
<li>为了刻画rerank的收益，rerank的目标是把交互的用户和item对排到最前面，可以用下述累积收益来刻画<br />
$$<br />
G = \sum_{u \sim user} \sum_{i \sim item} \frac{y_{ui} }{j}<br />
$$<br />
j 是rerank后的排序！上述收益可以刻画rerank的排序效果！</li>
<li>两个item是相似的，如果他们放在一起会导致效用下降<br />
$$<br />
P(y_i=1, y_j=1) &lt; P(y_i=1)P(y_j=1)<br />
$$<br />
如果feed流中有两个item是相似的，那么排序策略不是最优策略了！</li>
</ul>
<p><img alt="DPP" src="/wiki/static/images/dpp-serving.png" /></p>
<ul>
<li>有N个item，用0表示用户没有点，1表示点击，那么N个item对应的用户的行为向量为[0,..,1,..,0]，其中点击的下标服从行列式点过程！！因为下标是「当前元素小于前一个数」（假设1小于0），所以刚好是DPP中的那个例子！</li>
<li>
<p>因此用户点击的item下标服从DPP，点击下标集合Y的概率分布可以用一个矩阵的行列式来表示<br />
$$<br />
P(Y) = \frac{\det(L_Y)}{\sum_{Y ' \subset S} \det(L_{Y'})}<br />
$$<br />
S = {1,2,3,...,N}是全量下标集合。上式的分母可以简化为<br />
$$<br />
\sum_{Y ' \subset S} \det(L_{Y'}) = \det(L + I)<br />
$$</p>
</li>
<li>
<p>DPP核矩阵的定义，假设第i个video的Pointwise得分为$(q_i)$，sparse embedding向量为$(\phi_i)$。假设排序完有N个video，定义如下核矩阵<br />
$$<br />
L_{ii} = q_i^2 \\<br />
L_{ij} = \alpha q_i q_j \exp(- \frac{D_{ij}}{2\sigma^2}), i \neq j<br />
$$<br />
$(D_{ij})$是i和j的距离，通过embedding向量计算得到。</p>
</li>
<li>当$(\alpha)$较大的时候，代表斥力很大，但是就无法保证核矩阵的半正定要求。作者通过一个投影操作，将核矩阵强行半正定化。投影的方法是，将核矩阵对角化，然后将负特征值强行置0！</li>
<li>训练方法<ul>
<li>数据偏差，通过ee来实现</li>
<li>超参数$(\alpha, \sigma)$ 通过gridsearch来寻找</li>
</ul>
</li>
</ul>
<p><img alt="dpp-grid-search" src="/wiki/static/images/dpp-grid-search.png" width="400"></p>
<h3 id="deep-gramian-kernels">Deep Gramian Kernels</h3>
<ul>
<li>启发式的核矩阵，不容易分布式</li>
<li>直接用模型学习kernel矩阵</li>
<li>核矩阵的参数L有r个参数，用向量w表示。$(L = L(w))$</li>
<li>训练集： <ol>
<li>有N个items</li>
<li>用户有交互的item下标集合Y</li>
</ol>
</li>
<li>优化目标：极大似然估计出参数w，拟合实际的观测样本Y<br />
$$<br />
loglike(w) = \sum_j \log P(Y_j|w) = \sum_j \left[ \log \det(L(w) _ {Y_j}) - \log \det(I + L(w) _ {Y_j}) \right]<br />
$$</li>
<li>L的参数：item的embedding向量、质量分$(q_i)$向量（多个质量分维度，而不是最终的一个分数）<br />
$$<br />
L_{ij} = f(q_i)g(\phi_i)^T g(\phi_j)f(q_j) + \delta \mathbf{1}_{i=j}<br />
$$<br />
f和g是两个神经网络，f是标量，而g是一个向量，$(\delta)$是正则参数。这种方法可以保证L是半正定的，而不用投影！</li>
</ul>
<p><img alt="DPP核矩阵建模" src="/wiki/static/images/dpp-kernel-nn.png" width="400"></p>
<h3 id="efficient-ranking-algorithm-with-dpp">Efficient Ranking Algorithm with DPP</h3>
<ul>
<li>DPP layer接受到N个item的质量分q和video的embedding向量$(\phi)$</li>
<li>利用构造的方法或者神经网络的方法，计算出DPP的未归一化核矩阵L</li>
<li>选择固定的窗k &lt;&lt; N，寻找最大概率的k个item，放到上面，然后依次执行该步骤，选出余下的item并排序。之所以要选择一个窗口，而不是对全部N个item来排序，是因为相似item的斥力随着展示距离而衰减！换句话说，距离达到一定程度后是可以放很相似的item的。N一般是几百，而k一般是10+的样子。</li>
<li>最大化k个item出现的概率对应下列优化问题，是一个NP-hard问题<br />
$$<br />
\max_{Y:|Y|=k} \det(L_Y)<br />
$$</li>
<li>这个问题可以通过贪心算法近似求解，即从一个空集开始，每次加入一个item都要使得现有的k个item对应的$(\det(L_Y) )$是最大的！</li>
</ul>
<p><img alt="DPP算法" src="/wiki/static/images/dpp-rank-algo.png" width="400"></p>
<h3 id="_6">实验</h3>
<p>实验对比：<br />
<img alt="DPP实验结果" src="/wiki/static/images/dpp-exp-data.png" width="400"></p>
<ul>
<li>Fuzzy deduping：从空集开始，贪心地增加item：新增加的item如果和现有集合中的item距离小于一个阈值就干掉！</li>
<li>Sliding window：每m个item最多n个的距离可以小于一个阈值</li>
<li>Smooth score penalty：将相似作为惩罚系数<br />
$$<br />
q_{new, v} = q_{origin,v} * e^{-b(\phi_v \cdot \phi_{prev})} \\<br />
\phi_{prev} = \sum_{k=0}^{n} a^{n-k-1} \phi_k<br />
$$</li>
<li>这些方法都没有正向效果。只有DPP和Deep DPP有正向效果</li>
<li>对稀疏向量，使用Jaccard 距离应用到item token比较有效</li>
<li>核参数版本的DPP有明显正向效果，首页满意观看指标+0.63%，观看时长+0.52%。已经部署到TV，桌面，Live stream等场景。</li>
<li>Deep DPP虽然在第一个指标提升1.72%，但是由于对排序改动较大，对第二指标不利影响，仍需要继续调优！所以还没有部署。</li>
<li>长期学习效应：多样性带来更长期的收益，并且随着时间逐渐巩固！</li>
</ul>
<p><img alt="长期学习效应" src="/wiki/static/images/dpp-learning-effect.png" width="500"></p>
<h3 id="_7">结论和未来规划</h3>
<ul>
<li>多样性具有短期和长期双重收益</li>
<li>当前的多样性策略没有考虑用户的个性化、item的类型可能影响多样化需求。以及时间因素</li>
<li>未来会利用强化学习探索多样性的调控策略</li>
</ul>
<h3 id="_8">思考</h3>
<ul>
<li>DPP相比于传统的多样性方法，本质区别是什么？传统的方法还是将多样性作为一个目标，而DPP确实在优化用户交互这个目标，多样性是为了这个目标所必需的。简单地说，传统的方法是在优化多样性本身，DPP是在优化用户对列表的总交互量！</li>
</ul>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2019-11-05 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'Rerank机制调研',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2019 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>