<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>推荐论文集快速浏览 - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;<a href="/wiki/#-recommend">recommend</a>&nbsp;»&nbsp;推荐论文集快速浏览</div>
</div>
<div class="clearfix"></div>
<div id="title">推荐论文集快速浏览</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">论文列表</a></li>
<li><a href="#a-survey-on-session-based-recommender-systems">A Survey on Session-based Recommender Systems</a><ul>
<li><a href="#_2">历史</a></li>
<li><a href="#_3">未来的方向</a></li>
<li><a href="#_4">参考</a></li>
</ul>
</li>
<li><a href="#_5">基于规则的算法</a><ul>
<li><a href="#aprior">Aprior 算法</a></li>
<li><a href="#fp-tree">FP-Tree</a></li>
<li><a href="#fp">并行FP</a></li>
<li><a href="#fp_1">序列FP</a></li>
<li><a href="#_6">改进应用</a></li>
<li><a href="#_7">序列模式挖掘</a></li>
</ul>
</li>
<li><a href="#_8">推荐理由</a></li>
</ul>
</div>
<h2 id="_1">论文列表</h2>
<ul>
<li><a href="https://github.com/hongleizhang/RSPapers">https://github.com/hongleizhang/RSPapers</a></li>
</ul>
<h2 id="a-survey-on-session-based-recommender-systems">A Survey on Session-based Recommender Systems</h2>
<ul>
<li>基于session的推荐系统</li>
<li>基于内容的推荐(找相似内容)和基于协同过滤(利用用户行为找相似的人/物),偏静态,无法快速捕获用户的实时兴趣点的变化</li>
<li>将session作为推荐的基本单位而不是将用户作为基本单位</li>
<li>session的概念: A session is a set of items (e.g., referring to any objects, e.g., products, songs or movies) that are collected or consumed in one event (e.g., a transaction) or in a certain period of time or a collection of actions or events (e.g., listening to a song) that happened in a period of time (e.g., one hour).</li>
<li>即在一个事件(比如交易)中被获取或消费的一系列item的集合, 或者在一段时间内发生的动作或事件的集合</li>
<li>session推荐系统:Given partially known session information, e.g., part of a session or recent historical sessions, an SBRS aims to predict the unknown part of a session or the future sessions based on modelling the complex relations embedded within a session or between sessions.</li>
<li>即根据session的一部分来预测未知的部分、或者未来的session事件以及session之间的关联</li>
<li>两个方向: 推荐下一个/多个item; 推荐下一个session</li>
<li>基于session推荐: 基于session上下文预测target,有时也加入item特征和user特征</li>
</ul>
<p><img alt="SBRS" src="/static/images/sbrs.png" /></p>
<ul>
<li>item是基本单位,也是基于session的推荐系统的主要角色,其他的要么是描述item的特征,要么是组织item的结构如session</li>
<li>每个item都被多种特征所描述: item的类别,价格,位置等等</li>
<li>大多数情况下,item的相关性建模都基于他们的共现</li>
<li>关键挑战<ul>
<li>inner-session challenge</li>
<li>inter-session challenge</li>
<li>outer-session challenge</li>
</ul>
</li>
<li>session上下文: 时间、地点、天气、季节、用户; 这里将用户信息看做上下文信息</li>
<li>参考:<ol>
<li>Duc-Trong Le, Yuan Fang, and Hady W Lauw. 2016. Modeling sequential preferences with dynamic user and context factors. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 145–161.</li>
<li>Gediminas Adomavicius and Alexander Tuzhilin. 2011. Context-aware recommender systems. In Recommender systems handbook. Springer, 217–253</li>
<li>Longbing Cao. 2015. Coupling learning of complex interactions. Information Processing &amp; Management 51, 2 (2015), 167–186</li>
</ol>
</li>
<li>多样性挑战<ol>
<li>特征值的多样性,不同值出现的频率不大一样</li>
<li>特征类型的多样性</li>
<li>item的多样性,一些出现频率高二另外一些很少出现</li>
<li>session的多样性,不同上下文对当前session的相关性不一样,不知道是个什么鬼</li>
<li>上下文的多样性,很多不同类型的上下文因子,时间、地点</li>
</ol>
</li>
</ul>
<h3 id="_2">历史</h3>
<ul>
<li>最早始于1980年[1],</li>
<li>两个阶段: <ol>
<li>1990s-2010s, model-free阶段; 模式挖掘,关联规则挖掘,序列挖掘</li>
<li>2010s-今, Model-base阶段; 时间序列相关模型,马尔科夫链,RNN,DNN</li>
</ol>
</li>
<li>研究社区关注, [2-4]</li>
<li>what to recommend, 购物篮数据, 事件历史数据(movielens, POI)</li>
<li>how to recommend, 建模session内的依赖</li>
<li>item的顺序在某些场景非常重要,比如基因数据,但是在另外一些场景价值比较有限,比如加购物车的顺序。顺序关系比较重要的场景可以使用马尔科夫链、RNN等捕获序列关系的模型</li>
<li>不考虑顺序的模型,发觉共现规律</li>
<li>一阶依赖与高阶依赖, 一阶依赖:一阶马尔科夫链、因子机; 高阶依赖: 神经网络</li>
<li>session间依赖, 将上一个session也输入模型</li>
<li>item依赖模型,建模来自于不同session的item间的依赖: 因子机模型</li>
<li>集合依赖模型,将session中的item看做一个整体</li>
<li>特征级别的依赖, 功能互补的item经常出现在同一个session当中。 基于内容的推荐,解决冷启动的问题, 协同过滤。早期的推荐系统研究较多,基于session的推荐研究较少</li>
<li>技术类别:<ul>
<li>model-free 方法: <ol>
<li>基于模式/规则的方法, 关联挖掘, 牛奶和面包通常一起购买, 挖掘无序数据</li>
<li>基于序列模式的方法, 挖掘有序数据规律</li>
</ol>
</li>
<li>model-based方法:<ol>
<li>马尔科夫链</li>
<li>因子机方法</li>
<li>神经网络模型方法, 也叫 embedding模型和表示学习模型</li>
</ol>
</li>
</ul>
</li>
<li>
<p>不同方法的比较</p>
<ul>
<li>model-free方法:简单容易实现,对于复杂的数据和关系挖掘力不从心</li>
<li>model-based方法:能处理复杂的数据和关系挖掘,上限很高</li>
</ul>
</li>
<li>
<p>基于模式/规则的方法</p>
<ol>
<li>频率模式挖掘, Aprior、 FP-Tree, 如果P(i|s)概率高于某个阈值,就可以认为 <s, i>是一个高频模式</li>
<li>序列模式挖掘</li>
</ol>
</li>
<li>基于模型的方法<ol>
<li>马尔科夫链, 频率统计估计概率</li>
<li>马尔科夫embedding模型, 解决马尔科夫链稀疏的问题,不是用统计频率来估计转移概率,而是用embedding向量的欧式距离建模概率 $(P(i_1 \rightarrow i_2) = exp(-||v_{i_1} - v_{i_2}||^2) )$, 问题: 破坏了非对称性??</li>
<li>因子机模型, 为每个用户建立因子模型, $(A^{|U| \times |I| \times |I|})$, 每个元素代表某个用户从1个item转移到另一个item的转移概率。<ul>
<li>Tucker Decomposition, $(A = C \times V_U \times V_{I_j} \times V_{I_k})$, C是核心张量, $(V_U)$ 是用户特征矩阵,  $(V_{I_j})$和$(V_{I_k})$分别代表最后的item矩阵和下一个item矩阵。乘法分解</li>
<li>Canonical Decomposition, 加法分解。 $(a _ {u, i _ j, i _ k} = (v_u, v_{i_j}) + (v_u, v_{i_k}) + (v_{i_j}, v_{i_k}))$</li>
</ul>
</li>
<li>神经网络模型方法<ul>
<li>浅层网络, item2vec, user2vec, 在隐空间匹配</li>
<li>深层网络, RNN做序列推荐, GRU2Rec, DNN推荐, CNN</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="_3">未来的方向</h3>
<ul>
<li>用户通用偏好</li>
<li>利用用户显式偏好,长期偏好和短期偏好</li>
<li>更多上下文因子,</li>
<li>噪声和无关的item, 用户点击item的行为具有太多随机性了,怎样将随机性去除,而只将有规律的信号建模出来? attention, Pooling</li>
<li>多步推荐, Encoder-Decoder 框架?</li>
<li>cross-session information, 相当于偏长期一点的依赖</li>
<li>cross-domain information, 看了电影, 听对应的歌曲, transfer learning</li>
<li>非IID的时变问题</li>
</ul>
<h3 id="_4">参考</h3>
<p>[1] Ahmad M Ahmad Wasfi. 1998. Collecting user access patterns for building user profiles and collaborative filtering. In Proceedings of the 4th international conference on Intelligent user interfaces. ACM, 57–64<br />
[2] Balázs Hidasi, Alexandros Karatzoglou, Oren Sar-Shalom, Sander Dieleman, Bracha Shapira, and Domonkos Tikk. 2017. DLRS 2017: Second Workshop on Deep Learning for Recommender Systems. In Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 370–371.<br />
[3] Alexandros Karatzoglou and Balázs Hidasi. 2017. Deep Learning for Recommender Systems. In Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 396–397.<br />
[4] Alexandros Karatzoglou, Balázs Hidasi, Domonkos Tikk, Oren Sar-Shalom, Haggai Roitman, Bracha Shapira, and Lior Rokach. 2016. RecSys’ 16 Workshop on Deep Learning for Recommender Systems (DLRS). In Proceedings of the 10th ACM Conference on Recommender Systems. ACM, 415–416.<br />
[5] Shoujin Wang and Longbing Cao. 2017. Inferring implicit rules by learning explicit and hidden item dependency. IEEE Transactions on Systems, Man, and Cybernetics: Systems (2017)<br />
[6] Wei Wei, Xuhui Fan, Jinyan Li, and Longbing Cao. 2012. Model the complex dependence structures of financial variables by using canonical vine. In CIKM’12. 1382–1391.<br />
[7] Jia Xu and Longbing Cao. 2018. Vine Copula-Based Asymmetry and Tail Dependence Modeling. In PAKDD’2018, Part I. 285–297.</p>
<h2 id="_5">基于规则的算法</h2>
<h3 id="aprior">Aprior 算法</h3>
<ul>
<li>item集合 I , 也就是要推荐的东西的集合,比如商品集合,poi集合, I</li>
<li>session集合 S, 每条记录s代表一个item list,表明他们之间存在某种关联,比如同时在一个订单中出现, 同时在用户的一个session中出现等等。 s是 I的子集</li>
<li>支持度 $(support(A =&gt; B) = P(A \union B) )$, A和B都是I的子集, 支持度高的规则可以用来做推荐, 例如A是用户已经点击过的item集合,如果support(A =&gt; B)很大,那么就可以认为B是要给用户推荐的item集合。联合概率</li>
<li>置信度 $(confidence(A =&gt; B) = P(B | A) = \frac{P(A \union B)}{P(A)})$, 条件概率</li>
<li>强关联规则, 满足最小支持度和最小置信度的关联规则</li>
<li>由于任何(k-1)非频繁项集都不是k频繁项集的子集,所以在构建的时候可以减枝,在生产k项集的时候,可以只考虑k-1频繁项集的扩展集合即可</li>
</ul>
<h3 id="fp-tree">FP-Tree</h3>
<ul>
<li>论文:Mining frequent patterns without candidate generation, 韩家伟</li>
<li>并行版本实现: parallel fp-growth for query recommendation, Spark ml 库使用的方法</li>
<li>Frequent Pattern Tree</li>
<li>关键是构建FP树<ol>
<li>遍历整个数据集, 统计出每个item的次数,只保留超过最小支持度的item</li>
<li>将每条记录中的item按照item的全局频次排序</li>
<li>将排序号的列表插入到FP树中, 直到所有数据插入完成, 得到一个包含了数据集所有统计信息的数据结构</li>
</ol>
</li>
<li>FP树包含了用于频繁模式挖掘的所有信息, 是完备的</li>
<li>FP树构建复杂度分析<ol>
<li>只需要扫描数据库两次, 1次统计每个item的次数, 1次构建树</li>
<li>时间复杂度是 O(|transaction|)</li>
</ol>
</li>
<li>FP树的高度不超过每个transaction中频繁item的数目最大值</li>
<li>FP树节点的数目不超过全部transaction中频繁item的数目总和</li>
</ul>
<p><img alt="FP Tree" src="/wiki/static/images/fp-tree.png" /></p>
<ul>
<li>根据FP树寻找频繁集算法 FP-Growth, 扫描数据库,构建主FP树,然后执行一下算法,初始后缀为空集<ol>
<li>对FP树中的每个item,寻找以item结尾的所有路径构造子FP树,每个节点的次数也调整为item的次数。相当于从原始数据库中只筛选出包含item的transaction,并且去掉频率比item低的其他元素,构建FP树。去掉频度低的是为了避免重复统计。</li>
<li>在每个子FP树递归使用该算法,寻找频繁子串,直到FP树为空,或者item的所有路径上的频率之和不超过最小支持度。这些频繁子串与后缀拼接,得到完整的频繁子串</li>
</ol>
</li>
</ul>
<p><img alt="FP Growth" src="/wiki/static/images/fp-growth.png" /></p>
<h3 id="fp">并行FP</h3>
<ul>
<li>论文: parallel fp-growth for query recommendation, Spark ml 库使用的方法, Google China, 2008</li>
</ul>
<h3 id="fp_1">序列FP</h3>
<ul>
<li>论文: PrefixSpan- Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth</li>
<li>。。。</li>
</ul>
<h3 id="_6">改进应用</h3>
<ul>
<li>PV时间加权来计算规则的加权频率</li>
<li>引入用户个性化: 用户聚类</li>
<li>对关联规则加权,用规则中item的某种权重,都是手工设计的</li>
<li>将协同过滤和关联规则结合起来</li>
</ul>
<h3 id="_7">序列模式挖掘</h3>
<ul>
<li>Effective next-items recommendation via personalized sequential pattern mining, 2012</li>
</ul>
<h2 id="_8">推荐理由</h2>
<ul>
<li>Explainable Recommendation: A Survey and New Perspectives</li>
</ul>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2019-05-20 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '推荐论文集快速浏览',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2019 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>