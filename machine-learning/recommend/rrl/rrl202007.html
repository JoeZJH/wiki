<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>推荐系统评论快报-20年07期 - Tracholar的个人wiki</title>
        <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
        <meta name="description" content="A wiki website of tracholar when I learned new knowledgy and technics."/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            <div id="google-search" style="width:200px; float:right; margin: 20px 0;">
                <form action="//cse.google.com/cse" method="get" id="search-form">
                    <input type="hidden" name="cx" value="015970462532790426975:gqlen38ywus"/>
                    <input type="text" name="q"  style="line-height:20px; padding:4px;" placeholder="站内搜索"/>
                    <svg width="13" height="13" viewBox="0 0 13 13" style="position:relative; left: -20px;" onclick="document.getElementById('search-form').submit()">
                        <title>搜索</title>
                        <path d="m4.8495 7.8226c0.82666 0 1.5262-0.29146 2.0985-0.87438 0.57232-0.58292 0.86378-1.2877 0.87438-2.1144 0.010599-0.82666-0.28086-1.5262-0.87438-2.0985-0.59352-0.57232-1.293-0.86378-2.0985-0.87438-0.8055-0.010599-1.5103 0.28086-2.1144 0.87438-0.60414 0.59352-0.8956 1.293-0.87438 2.0985 0.021197 0.8055 0.31266 1.5103 0.87438 2.1144 0.56172 0.60414 1.2665 0.8956 2.1144 0.87438zm4.4695 0.2115 3.681 3.6819-1.259 1.284-3.6817-3.7 0.0019784-0.69479-0.090043-0.098846c-0.87973 0.76087-1.92 1.1413-3.1207 1.1413-1.3553 0-2.5025-0.46363-3.4417-1.3909s-1.4088-2.0686-1.4088-3.4239c0-1.3553 0.4696-2.4966 1.4088-3.4239 0.9392-0.92727 2.0864-1.3969 3.4417-1.4088 1.3553-0.011889 2.4906 0.45771 3.406 1.4088 0.9154 0.95107 1.379 2.0924 1.3909 3.4239 0 1.2126-0.38043 2.2588-1.1413 3.1385l0.098834 0.090049z">
                        </path>
                    </svg>
                </form>

            </div>
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#machine-learning">machine-learning</a>&nbsp;»&nbsp;<a href="/wiki/#-recommend">recommend</a>&nbsp;»&nbsp;<a href="/wiki/#-rrl">rrl</a>&nbsp;»&nbsp;推荐系统评论快报-20年07期</div>
</div>
<div class="clearfix"></div>
<div id="title">推荐系统评论快报-20年07期</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#autoint">AutoInt</a><ul>
<li><a href="#_1">主要内容</a><ul>
<li><a href="#_2">模型</a></li>
<li><a href="#_3">试验</a></li>
</ul>
</li>
<li><a href="#_4">评论</a></li>
</ul>
</li>
<li><a href="#tfnet">TFNet</a><ul>
<li><a href="#_5">主要内容</a><ul>
<li><a href="#_6">模型</a></li>
<li><a href="#_7">试验结果</a></li>
</ul>
</li>
<li><a href="#_8">评论</a></li>
</ul>
</li>
<li><a href="#nn">时空NN</a><ul>
<li><a href="#_9">主要内容</a><ul>
<li><a href="#_10">模型</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#id">唯一ID生成算法</a><ul>
<li><a href="#_11">主要内容</a></li>
</ul>
</li>
<li><a href="#_12">噪声、正则与泛化</a><ul>
<li><a href="#_13">主要内容</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="autoint">AutoInt</h2>
<ul>
<li>论文：AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks，CIKM 2019</li>
<li>基本思想：用self-attention来学习特征交叉</li>
<li>代码：<a href="https://github.com/DeepGraphLearning/RecommenderSystems">https://github.com/DeepGraphLearning/RecommenderSystems</a></li>
</ul>
<h3 id="_1">主要内容</h3>
<h4 id="_2">模型</h4>
<p><img src="/wiki/static/images/autoint-01.png" style="max-width:400px" /></p>
<ul>
<li>将所有的特征当做稀疏特征，投影到同一个emb低维空间，得到向量序列e1,...,eM<ol>
<li>对单值特征，直接emb</li>
<li>单值连续值特征，emb后乘以连续值</li>
<li>对多值特征，emb后取平均</li>
</ol>
</li>
</ul>
<p><img src="/wiki/static/images/autoint-02.png" style="max-width:300px" /></p>
<ul>
<li>交互层，将上述每个emb依次看做query，利用self-attention实现特征间的交互，<br />
  利用多头Attention每个向量都可得到H个变换后的向量，拼接得到交叉特征$(\tilde{e_m} = \tilde{e_m}^1 \oplus ... \oplus \tilde{e_m}^H)$</li>
</ul>
<p><img src="/wiki/static/images/autoint-03.png" style="max-width:200px" /><br />
<img src="/wiki/static/images/autoint-04.png" style="max-width:200px" /><br />
<img src="/wiki/static/images/autoint-05.png" style="max-width:400px" /></p>
<ul>
<li>
<p>将多头变化后的向量$(\tilde{e_m})$跟原始向量$(e_m)$用残差方式融合得到最终向量。<br />
$$<br />
e_m^{Res} = ReLU(\tilde{e_m} + W_{Res} e_m)<br />
$$</p>
</li>
<li>
<p>进过上述交叉层后，每个$(e_m)$都得到一个融合特征交叉后的$(e_m^{Res})$。<br />
  concat后进入逻辑回归层，预测概率即可。</p>
</li>
</ul>
<h4 id="_3">试验</h4>
<ul>
<li>实验结果显示，相比于其他实现交叉的方法，在离线指标上有显著提升。</li>
<li>残差对结果提升较大，self-attention层数不用太多2-4层即可。</li>
<li>交互层对模型训练性能影响还比较大。</li>
</ul>
<p><img src="/wiki/static/images/autoint-06.png" style="max-width:400px" /><br />
<img src="/wiki/static/images/autoint-07.png" style="max-width:600px" /></p>
<h3 id="_4">评论</h3>
<ul>
<li>利用self-attention来做特征间的交叉是个不错的想法，但是self-attention的<br />
  物理意义应该是用其他特征向量来平滑中间特征向量，直观上来看有点说不太通。至少<br />
  在这个点上，可以做一些改进，比如$(\tilde{e_m}^h)$不是用所有特征向量的线性组合，<br />
  而是用特征间内积的线性组合，可能更能表示特征间的交叉。</li>
<li>另外，由于不同的特征的emb尺寸是一样的，可能会影响高基数特征的表达能力，因为<br />
  这个尺寸大家必须相同，所以不会特别大，而很多id特征的基数很高，如果比较重要的话，<br />
  提高这部分特征的emb尺寸是有一定价值的。但是在autoint中，强行让所有的emb尺寸都相同，<br />
  从理论上来分析，可能会有一定的负面效果。当然，最终以试验结果为准，炼丹大分部都是玄学。</li>
<li>实际上，可以对self-attention稍加改造就可以不需要让每个特征的emb尺寸保持一致。<br />
  在计算内积的时候增加一个投影即可，所以维度不匹配的地方都可以通过一个投影来实现维度匹配。</li>
<li>复杂度从实验结果来看，在合理的范围内，可以在实际场景中试试。</li>
</ul>
<h2 id="tfnet">TFNet</h2>
<ul>
<li>论文：TFNet: Multi-Semantic Feature Interaction for CTR Prediction，2020</li>
<li>主要思想：之前的特征交叉利用向量乘法对特征对进行交叉，忽略了不同语义空间的交叉！？？</li>
</ul>
<h3 id="_5">主要内容</h3>
<h4 id="_6">模型</h4>
<p><img src="/wiki/static/images/tfnet-01.png" style="max-width:600px" /></p>
<ul>
<li>embedding输入层：n个特征，n个field，每个field通过embedding映射到一个d维向量vi。</li>
<li>基于张量的语义交叉，对任意两个特征向量vi，vj，用3阶张量$( T1\in  R^{d\times m \times d})$交叉<br />
$$<br />
s_{ij} = vi T1 vj \in R^{m}<br />
$$</li>
<li>所有的特征对的交叉构成了矩阵$( S \in R^{q\times m} )$，q=n(n-1)/2</li>
<li>自适应门控，认为每个语义空间重要性不一样。<br />
$$<br />
T1 = g_a \odot T2<br />
$$</li>
<li>Attention权重ga通过第3个张量$(T3\in R^{d\times m \times d})$学到<br />
$$<br />
g_a = softmax(v_i^T T3 v_j)<br />
$$</li>
<li>控制门$(gc \in R^q)$，不是所有学到的新特征都有用，用这个门控制只选取有用的特征。<br />
  用L1范数限制他稀疏，同时要求非负。最终输出的向量$(s_h = S^T g_c \in R^m)$</li>
<li>高阶交互，后续通过一个DNN实现高阶交互。</li>
<li>输出层，将原始特征、DNN输出向量、跟TFnet的输出concat后，经过逻辑回归层输出概率。</li>
</ul>
<h4 id="_7">试验结果</h4>
<ul>
<li>评估指标，RI-X X是普通指标时为相对提升，X为AUC是减掉0.5之后的相对提升。</li>
<li>离线试验，对比了FM，W&amp;D，DeepFM，NFM，AFM</li>
</ul>
<p><img src="/wiki/static/images/tfnet-02.png" style="max-width:400px" /></p>
<ul>
<li>在线评估<br />
<img src="/wiki/static/images/tfnet-03.png" style="max-width:400px" /></li>
</ul>
<h3 id="_8">评论</h3>
<ul>
<li>所谓的基于张量的语义交叉，就是一个简单的双线性变换嘛，包装过头了！</li>
<li>总的来说是一篇比较普通的文章，没有证实每个部分的必要性，T1,T2,T3，哪个是不可少的？<br />
  但是交叉的思想还是有一定参考意义。</li>
</ul>
<h2 id="nn">时空NN</h2>
<ul>
<li>论文：Deep Spatio-Temporal Neural Networks for Click-Through Rate Prediction，2019</li>
<li>神马搜索，利用辅助数据，利用同页面上的上下文广告，点击跟未点击数据</li>
</ul>
<p><img src="/wiki/static/images/stnn-01.png" style="max-width:400px" /></p>
<h3 id="_9">主要内容</h3>
<h4 id="_10">模型</h4>
<p><img src="/wiki/static/images/stnn-02.png" style="max-width:400px" /></p>
<ul>
<li>特征embedding<ul>
<li>单值cat特征，直接embedding</li>
<li>多值cat特征，embedding后sumpooling</li>
<li>连续特征，离散化后embedding</li>
</ul>
</li>
<li>经过embedding层后，得到target ad向量 xt，nc个上下文广告向量xc，nl个点击广告向量xl，<br />
  nu个未点击广告向量xu</li>
<li>DSTN - Pooling Model：直接sumpooling融合多个广告向量</li>
<li>DSTN - Self-Attention Model：Attention权重来自于自己，且跟其他特征无关<br />
  （这个是跟NLP中的self-attention不一样的点），没有什么意义</li>
<li>DSTN - Interactive Attention Model：用target ad向量xt跟广告向量一起算<br />
  Attention权重。</li>
</ul>
<h2 id="id">唯一ID生成算法</h2>
<ul>
<li>推荐理由：是一个比较关键的基础算法，可以适当了解一下</li>
<li>博客：<a href="https://zhuanlan.zhihu.com/p/154480290">https://zhuanlan.zhihu.com/p/154480290</a></li>
</ul>
<h3 id="_11">主要内容</h3>
<ul>
<li>用途：分布式场景的唯一标识</li>
<li>唯一ID需要满足的要求<ol>
<li>全局唯一性：不能出现重复的 ID 号，既然是唯一标识，这是最基本的要求；</li>
<li>趋势递增：在 MySQL InnoDB 引擎中使用的是聚集索引，由于多数 RDBMS <br />
   使用 B-tree 的数据结构来存储索引数据，在主键的选择上面我们应该尽量<br />
   使用有序的主键保证写入性能；</li>
<li>单调递增：保证下一个 ID 一定大于上一个 ID，例如事务版本号、IM 增量消息、<br />
   排序等特殊需求；</li>
<li>信息安全：如果 ID 是连续的，恶意用户的爬取工作就非常容易做了，直接按照<br />
   顺序下载指定 URL 即可；如果是订单号就更危险了，竞争对手可以直接知道我们<br />
   一天的单量。所以在一些应用场景下，会需要 ID 无规则、不规则。</li>
</ol>
</li>
<li>UUID算法（Universally Unique Identifier），uuid有以下几部分组成<ul>
<li>当前日期和时间，UUID的第一个部分与时间有关</li>
<li>时钟序列。</li>
<li>全局唯一的IEEE机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得</li>
</ul>
</li>
<li>Snowflake，Twitter 2010，Snowflake 以 64 bit 来存储组成 ID 的4 个部分：<br />
    1、最高位占1 bit，值固定为 0，以保证生成的 ID 为正数；<br />
    2、中位占 41 bit，值为毫秒级时间戳；<br />
    3、中下位占 10 bit，值为工作机器的 ID，值的上限为 1024；<br />
    4、末位占 12 bit，值为当前毫秒内生成的不同 ID，值的上限为 4096；</li>
<li>百度 <a href="https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md">UIDGenerator</a></li>
</ul>
<h2 id="_12">噪声、正则与泛化</h2>
<ul>
<li>公众号文章：<a href="https://mp.weixin.qq.com/s/b6dTrFgwCjpusWdclB6UXw">泛化性乱弹：从随机噪声、梯度惩罚到虚拟对抗训练</a></li>
<li>作者苏剑林写过很多不错的技术文章，而且文笔很好，思考得也有深度，值得我们学习。</li>
</ul>
<h3 id="_13">主要内容</h3>
</div>
<div id="income">
    <!--img src="/wiki/static/images/support-qrcode.png" alt="支持我" style="max-width:300px;" /-->

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2020-07-01 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '推荐系统评论快报-20年07期',
  owner: 'tracholar',
  repo: 'wiki',
  oauth: {
    client_id: '0cc0476e504b5e70ae7c',
    client_secret: 'ab98e39ef79469040057eba9c6b2b543b84c72ee',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2020 tracholar.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>