---
title: "推荐系统在工业界的调研"
layout: page
date: 2020-03-05
---

[TOC]

# 产品形态
## Feed
- 电商类：
    - 淘宝首页的猜你喜欢
    - 京东首页的为你推荐
    - 拼多多首页Feed
    - 美团首页的猜你喜欢
    - 大众点评首页Feed
- 资讯新闻类：
    - 头条首页Feed
    - 腾讯新闻Feed
    - 知乎推荐
    - 微信搜一搜
    - 百度百家号
- 视频类：
    - 抖音
    - 快手
    - YouTube视频推荐

## 交互式推荐
- [淘宝风向标](https://mp.weixin.qq.com/s/oY9BBjAHUKZr6dVdnNtcbg)
- 视频feed：腾讯、爱奇艺 etc

# 目标
- 商业目标：GMV，时长，DAU etc
- 建模目标：CTR，CVR，price etc

# 召回
- 策略召回：
    - 热门：热门新闻，热门商家
    - 附近：附近发生的新闻，附近商家
    - 好友推荐：好友点赞/看过的
- 基于内容：
    - 利用文本和图片等特征计算item相似度，然后推荐跟用户交互过的item相似的item。也是item2item的一种
- 协同过滤（CF）：基于行为共现关系
    - UserCF：lookalike?
    - ItemCF：(item2item)
        - 共现矩阵计算相似，基本不用了
        - 构造item共现矩阵，矩阵分解得到item向量(ALS算法)，取最近邻(近似最近邻Annoy，Faiss)
        - item2vec，构造共现序列（一般用session或者订单）利用word2vec，学出item向量，取最近邻
        - GraphEmbedding：node2vec，randomwalk。构造session图或者语义图，利用随机游走采样序列，变成item2vec问题
- U2I
    - 构造user-item共现矩阵，矩阵分解得到item向量(ALS算法)，取最近邻(近似最近邻Annoy，Faiss)
    - YouTube DNN，将用户向量用一个DNN来建模，监督信号使用点击/下单
    - DSSM，用户向量和item向量都用DNN建模，但是item不使用实时特征。监督信号使用点击/下单



# 排序
- 离散LR，可以使用大规模离散id特征，提高模型容量和个性化。缺点是需要大量特征工程：人工交叉特征，或者用GBDT来交叉特征。曾经线上的主力模型，现在也做粗排模型用
- GBDT，统计特征居多，难以处理大规模离散特征。也是较好的baseline，缺点是跟DNN这套体系不太相容，随着数据量增大，模型容量容易接近天花板
- wide & deep，实际上就是 离散DNN + LR，这里特意强调离散DNN，指的是利用embedding来扩充模型容量的DNN。解决了单独LR的特征工程问题。当前的新基线模型，也是线上主力
- 其他改进：DeepFM、DCN、DIN(加了Attention)，DIEN（加了RNN对行为序列建模）。这些改进常常取决于数据和问题场景，有些有效果，有些不见得有效果。理论上有效果，实际也不一定有效果。需要一个个去试，权衡成本跟收益
- TDM：将召回和排序联合训练，目前只有阿里在用

# 多目标
- 多任务学习：
    - 共享一些底层embedding和层。知乎、微博
    - 给预测目标增加额外约束。美团，阿里
    - MMOE：除了共享底层表达，在中间的变换层用多个子网络来做，避免任务间的负迁移，然后用Attention融合子网络的结果，做到不同建模目标侧重不同的子网络
- 多目标融合：多个目标融合的权重调参，优化目标是多个「商业目标」。目标表优化问题，找到帕累托最优
    - 离线近似调参+线上AB测试
    - CEM：当做黑盒优化问题，用CEM在线调参
    - 贝叶斯优化：当做黑和优化问题，用贝叶斯优化在线调参

# 重排与机制
- 重排：主要解决排序只考虑单个item，而实际上是给出一个item列表，使得整个列表的收益最大化。一个极端的例子是，排在前面的都是用户喜欢的，但是基本上一模一样。
    - 规则：通过启发式规则，限制一定范围内的item的相似度；强查etc
    - DPP：行列式点过程建模相似item的互斥关系，YouTube有落地
    - RNN：阿里有尝试，将上下文item的特征都加进去，将重排建模成一个Decoder问题
- 机制：某些场景下的推荐并不是重排问题，比如滴滴打车的用户司机匹配（如果看做推荐的话），这类问题一般可以建模成一个待约束的组合优化问题
    - 数学优化求解
    - 强化学习暴利求解

# 其他主题
## 冷启动，EE
- 汤普森采样
- 贝叶斯方法：BOPR
- 自然梯度：NGBoost

## 在线学习
- FTRL

## 强化学习
- 目前强化主要来解决几个问题
    - 数据有偏：YouTube
    - 长期收益：阿里的一些工作
    - 交互式推荐中的序列决策问题：淘宝锦囊
## GAN
- 暂时缺乏公开的有重要意义的成果

# FAQ
